{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For more details on surrogate gradient learning, please see: \n",
    "> Neftci, E.O., Mostafa, H., and Zenke, F. (2019). Surrogate Gradient Learning in Spiking Neural Networks.\n",
    "> https://arxiv.org/abs/1901.09948"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Training a spiking neural network on a simple vision dataset\n",
    "\n",
    "Friedemann Zenke (https://fzenke.net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Tutorial 2, we have seen how to train a simple multi-layer spiking neural network on the [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist). However, the spiking activity in the hidden layer was not particularly plausible in a biological sense. Here we modify the network from this previous tutorial by adding activity regularizer, which encourages solutions with sparse spiking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coarse network structure is dicated by the Fashion MNIST dataset. \n",
    "nb_inputs  = 28*28\n",
    "nb_hidden  = 100\n",
    "nb_outputs = 10\n",
    "\n",
    "time_step = 1e-2\n",
    "nb_steps  = 100\n",
    "\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "\n",
    "# Check whether a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")     \n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we load the Dataset\n",
    "root = os.path.expanduser(\"~/data/datasets/torch/mnist\")\n",
    "train_dataset = torchvision.datasets.MNIST(root, train=True, transform=None, target_transform=None, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root, train=False, transform=None, target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joshua\\AppData\\Local\\Temp\\ipykernel_11492\\1224777063.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x_train = np.array(train_dataset.data, dtype=np.float)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Temp\\ipykernel_11492\\1224777063.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x_test = np.array(test_dataset.data, dtype=np.float)\n"
     ]
    }
   ],
   "source": [
    "# Standardize data\n",
    "# x_train = torch.tensor(train_dataset.train_data, device=device, dtype=dtype)\n",
    "x_train = np.array(train_dataset.data, dtype=np.float)\n",
    "x_train = x_train.reshape(x_train.shape[0],-1)/255\n",
    "# x_test = torch.tensor(test_dataset.test_data, device=device, dtype=dtype)\n",
    "x_test = np.array(test_dataset.data, dtype=np.float)\n",
    "x_test = x_test.reshape(x_test.shape[0],-1)/255\n",
    "\n",
    "# y_train = torch.tensor(train_dataset.train_labels, device=device, dtype=dtype)\n",
    "# y_test  = torch.tensor(test_dataset.test_labels, device=device, dtype=dtype)\n",
    "y_train = np.array(train_dataset.targets, dtype=np.int64)\n",
    "y_test  = np.array(test_dataset.targets, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we plot one of the raw data points as an example\n",
    "data_id = 2\n",
    "plt.imshow(x_train[data_id].reshape(28,28), cmap=plt.cm.gray_r)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are working with spiking neural networks, we ideally want to use a temporal code to make use of spike timing. To that end, we will use a spike latency code to feed spikes to our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current2firing_time(x, tau=20, thr=0.3, tmax=1.0, epsilon=1e-7):\n",
    "    \"\"\" Computes first firing time latency for a current input x assuming the charge time of a current based LIF neuron.\n",
    "\n",
    "    Args:\n",
    "    x -- The \"current\" values\n",
    "\n",
    "    Keyword args:\n",
    "    tau -- The membrane time constant of the LIF neuron to be charged\n",
    "    thr -- The firing threshold value \n",
    "    tmax -- The maximum time returned \n",
    "    epsilon -- A generic (small) epsilon > 0\n",
    "\n",
    "    Returns:\n",
    "    Time to first spike for each \"current\" x\n",
    "    \"\"\"\n",
    "    idx = x<thr\n",
    "    x = np.clip(x,thr+epsilon,1e9)\n",
    "    T = tau*np.log(x/(x-thr))\n",
    "    T[idx] = tmax\n",
    "    return T\n",
    "\n",
    "def spike_fn(x):\n",
    "    out = torch.zeros_like(x)\n",
    "    out[x > 0] = 1.0\n",
    "    return out\n",
    "        \n",
    "def sparse_data_generator(X, y, batch_size, nb_steps, nb_units, shuffle=True ):\n",
    "    \"\"\" This generator takes datasets in analog format and generates spiking network input as sparse tensors. \n",
    "\n",
    "    Args:\n",
    "        X: The data ( sample x event x 2 ) the last dim holds (time,neuron) tuples\n",
    "        y: The labels\n",
    "    \"\"\"\n",
    "\n",
    "    labels_ = np.array(y,dtype=np.int64)\n",
    "    number_of_batches = len(X)//batch_size\n",
    "    sample_index = np.arange(len(X))\n",
    "\n",
    "    # compute discrete firing times\n",
    "    tau_eff = 20e-3/time_step\n",
    "    firing_times = np.array(current2firing_time(X, tau=tau_eff, tmax=nb_steps), dtype=np.int64)\n",
    "    unit_numbers = np.arange(nb_units)\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "\n",
    "    total_batch_count = 0\n",
    "    counter = 0\n",
    "    while counter<number_of_batches:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "\n",
    "        coo = [ [] for i in range(3) ]\n",
    "        for bc,idx in enumerate(batch_index):\n",
    "            \n",
    "            batch = [bc for _ in range(len(times))]\n",
    "            coo[0].extend(batch)\n",
    "            \n",
    "\n",
    "        i = torch.LongTensor(coo).to(device)\n",
    "        v = torch.FloatTensor(np.ones(len(coo[0]))).to(device)\n",
    "    \n",
    "        X_batch = torch.sparse.FloatTensor(i, v, torch.Size([batch_size,nb_steps,nb_units])).to(device)\n",
    "        y_batch = torch.tensor(labels_[batch_index],device=device)\n",
    "\n",
    "        yield X_batch.to(device=device), y_batch.to(device=device)\n",
    "\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_image(image, scale, time_step):\n",
    "    scaled_image = image*scale\n",
    "    for i,prob in enumerate(scaled_image):\n",
    "        if (prob > 1):\n",
    "            new_prob = 1\n",
    "            scaled_image[i] = new_prob\n",
    "    rate_of_scaled_image = scaled_image/time_step\n",
    "    average_rate = torch.mean(rate_of_scaled_image)\n",
    "    return scaled_image, average_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images2spike(x, y, batch_size, shuffle, **kwargs):  \n",
    "    '''Converts images to spike trains'''\n",
    "    labels_ = np.array(y,dtype=np.int64)\n",
    "    number_of_batches = len(x)//batch_size\n",
    "    sample_index = np.arange(len(x))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "\n",
    "    total_batch_count = 0\n",
    "    counter = 0\n",
    "\n",
    "    batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "    while counter < number_of_batches:\n",
    "        x_batch = torch.empty((len(x[batch_index]), nb_steps, nb_inputs)).to(device)\n",
    "        for i, image in enumerate(x[batch_index]):\n",
    "            tensor_image = torch.Tensor(image) # probabilities tensor\n",
    "            zero_image = torch.zeros(tensor_image.shape)\n",
    "            spike_train = torch.empty((nb_steps, nb_inputs))\n",
    "            for t in range(nb_steps):\n",
    "                spike_t = torch.bernoulli(tensor_image)\n",
    "                spike_train[t] = spike_t\n",
    "            x_batch[i] = spike_train\n",
    "        y_batch = torch.tensor(labels_[batch_index],device=device) \n",
    "\n",
    "        yield x_batch,  y_batch\n",
    "\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup of the spiking network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "\n",
    "alpha   = float(np.exp(-time_step/tau_syn))\n",
    "beta    = float(np.exp(-time_step/tau_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init done\n"
     ]
    }
   ],
   "source": [
    "weight_scale = 0.01\n",
    "\n",
    "w1 = torch.empty((nb_inputs, nb_hidden),  device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w1, mean=0.0, std=weight_scale)\n",
    "\n",
    "w2 = torch.empty((nb_hidden, nb_outputs), device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w2, mean=0.0, std=weight_scale)\n",
    "\n",
    "print(\"init done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_voltage_traces(mem, spk=None, dim=(3,5), spike_height=5):\n",
    "    gs=GridSpec(*dim)\n",
    "    if spk is not None:\n",
    "        dat = 1.0*mem\n",
    "        dat[spk>0.0] = spike_height\n",
    "        dat = dat.detach().cpu().numpy()\n",
    "    else:\n",
    "        dat = mem.detach().cpu().numpy()\n",
    "    for i in range(np.prod(dim)):\n",
    "        if i==0: a0=ax=plt.subplot(gs[i])\n",
    "        else: ax=plt.subplot(gs[i],sharey=a0)\n",
    "        ax.plot(dat[i])\n",
    "        ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurrGradSpike(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Here we implement our spiking nonlinearity which also implements \n",
    "    the surrogate gradient. By subclassing torch.autograd.Function, \n",
    "    we will be able to use all of PyTorch's autograd functionality.\n",
    "    Here we use the normalized negative part of a fast sigmoid \n",
    "    as this was done in Zenke & Ganguli (2018).\n",
    "    \"\"\"\n",
    "    \n",
    "    scale = 100.0 # controls steepness of surrogate gradient\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we compute a step function of the input Tensor\n",
    "        and return it. ctx is a context object that we use to stash information which \n",
    "        we need to later backpropagate our error signals. To achieve this we use the \n",
    "        ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        out = torch.zeros_like(input)\n",
    "        out[input > 0] = 1.0\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor we need to compute the \n",
    "        surrogate gradient of the loss with respect to the input. \n",
    "        Here we use the normalized negative part of a fast sigmoid \n",
    "        as this was done in Zenke & Ganguli (2018).\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad = grad_input/(SurrGradSpike.scale*torch.abs(input)+1.0)**2\n",
    "        return grad\n",
    "    \n",
    "# here we overwrite our naive spike function by the \"SurrGradSpike\" nonlinearity which implements a surrogate gradient\n",
    "spike_fn  = SurrGradSpike.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_snn(inputs):\n",
    "    h1 = torch.einsum(\"abc,cd->abd\", (inputs, w1))\n",
    "    syn = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "    mem = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "\n",
    "    mem_rec = []\n",
    "    spk_rec = []\n",
    "\n",
    "    # Compute hidden layer activity\n",
    "    for t in range(nb_steps):\n",
    "        mthr = mem-1.0\n",
    "        out = spike_fn(mthr)\n",
    "        rst = out.detach() # We do not want to backprop through the reset\n",
    "\n",
    "        new_syn = alpha*syn +h1[:,t]\n",
    "        new_mem = (beta*mem +syn)*(1.0-rst)\n",
    "\n",
    "        mem_rec.append(mem)\n",
    "        spk_rec.append(out)\n",
    "        \n",
    "        mem = new_mem\n",
    "        syn = new_syn\n",
    "\n",
    "    mem_rec = torch.stack(mem_rec,dim=1)\n",
    "    spk_rec = torch.stack(spk_rec,dim=1)\n",
    "\n",
    "    # Readout layer\n",
    "    h2= torch.einsum(\"abc,cd->abd\", (spk_rec, w2))\n",
    "    flt = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out_rec = [out]\n",
    "    spk_rec2 = []\n",
    "    for t in range(nb_steps):\n",
    "        mthr = out-1.0\n",
    "        output = spike_fn(mthr)\n",
    "        rst = output.detach() # We do not want to backprop through the reset\n",
    "\n",
    "        new_flt = alpha*flt +h2[:,t]\n",
    "        new_out = (beta*out +flt)*(1.0-rst)\n",
    "\n",
    "        flt = new_flt\n",
    "        out = new_out\n",
    "\n",
    "        out_rec.append(out) # membrane potential\n",
    "        spk_rec2.append(output) # spike train\n",
    "\n",
    "    out_rec = torch.stack(out_rec,dim=1)\n",
    "    spk_rec2 = torch.stack(spk_rec2, dim=1)\n",
    "\n",
    "    return spk_rec2,  spk_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_data, y_data, scale=1, lr=1e-3, nb_epochs=10):\n",
    "    params = [w1,w2]\n",
    "    optimizer = torch.optim.Adamax(params, lr=lr, betas=(0.9,0.999))\n",
    "\n",
    "    log_softmax_fn = nn.LogSoftmax(dim=1)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    \n",
    "    loss_hist = []\n",
    "    for e in range(nb_epochs):\n",
    "        local_loss = []\n",
    "        for x_local, y_local in images2spike(x_data, y_data, batch_size, shuffle=True):\n",
    "            output, spks = run_snn(x_local)\n",
    "            spike_count =torch.sum(output,1)\n",
    "            mean_firing_rate = spike_count/(nb_steps*time_step)\n",
    "\n",
    "            log_p_y = log_softmax_fn(mean_firing_rate)\n",
    "            \n",
    "            # Here we set up our regularizer loss\n",
    "            # The strength paramters here are merely a guess and there should be ample room for improvement by\n",
    "            # tuning these paramters.\n",
    "            reg_loss = 1e-7*torch.sum(spks) # L1 loss on total number of spikes\n",
    "            reg_loss += 1e-8*torch.mean(torch.sum(torch.sum(spks,dim=0),dim=0)**2) # L2 loss on spikes per neuron\n",
    "\n",
    "            # Here we combine supervised loss and the regularizer\n",
    "            loss_val = loss_fn(log_p_y, y_local) \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "            local_loss.append(loss_val.item())\n",
    "        mean_loss = np.mean(local_loss)\n",
    "        print(\"Epoch %i: loss=%.5f\"%(e+1,mean_loss))\n",
    "        loss_hist.append(mean_loss)\n",
    "        \n",
    "    return loss_hist\n",
    "        \n",
    "        \n",
    "def compute_classification_accuracy(x_data, y_data, batch_size, shuffle, **kwargs):\n",
    "    \"\"\" Computes classification accuracy on supplied data in batches. \"\"\"\n",
    "    accs = []\n",
    "    for x_local, y_local in images2spike(x_data, y_data, batch_size, shuffle=True, **kwargs):\n",
    "        output, _ = run_snn(x_local)\n",
    "        spike_count =torch.sum(output,1)\n",
    "        mean_firing_rate = spike_count/(nb_steps*time_step)\n",
    "        _, am = torch.max(mean_firing_rate, 1)\n",
    "        tmp = np.mean((y_local==am).detach().cpu().numpy()) # compare to labels\n",
    "        accs.append(tmp)\n",
    "    return np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=2.14797\n",
      "Epoch 2: loss=1.34097\n",
      "Epoch 3: loss=0.67477\n",
      "Epoch 4: loss=0.39669\n",
      "Epoch 5: loss=0.34825\n",
      "Epoch 6: loss=0.38511\n",
      "Epoch 7: loss=0.17316\n",
      "Epoch 8: loss=0.27005\n",
      "Epoch 9: loss=0.34094\n",
      "Epoch 10: loss=0.24919\n",
      "Epoch 11: loss=0.33855\n",
      "Epoch 12: loss=0.27334\n",
      "Epoch 13: loss=0.33275\n",
      "Epoch 14: loss=0.23456\n",
      "Epoch 15: loss=0.22802\n",
      "Epoch 16: loss=0.12870\n",
      "Epoch 17: loss=0.32645\n",
      "Epoch 18: loss=0.23443\n",
      "Epoch 19: loss=0.12530\n",
      "Epoch 20: loss=0.13432\n",
      "Epoch 21: loss=0.21613\n",
      "Epoch 22: loss=0.22903\n",
      "Epoch 23: loss=0.18211\n",
      "Epoch 24: loss=0.15036\n",
      "Epoch 25: loss=0.17570\n",
      "Epoch 26: loss=0.13659\n",
      "Epoch 27: loss=0.16198\n",
      "Epoch 28: loss=0.14738\n",
      "Epoch 29: loss=0.14577\n",
      "Epoch 30: loss=0.09248\n",
      "Epoch 31: loss=0.15356\n",
      "Epoch 32: loss=0.12966\n",
      "Epoch 33: loss=0.15326\n",
      "Epoch 34: loss=0.14209\n",
      "Epoch 35: loss=0.11043\n",
      "Epoch 36: loss=0.13962\n",
      "Epoch 37: loss=0.16623\n",
      "Epoch 38: loss=0.22655\n",
      "Epoch 39: loss=0.10256\n",
      "Epoch 40: loss=0.13804\n",
      "Epoch 41: loss=0.09451\n",
      "Epoch 42: loss=0.24090\n",
      "Epoch 43: loss=0.15261\n",
      "Epoch 44: loss=0.23515\n",
      "Epoch 45: loss=0.08925\n",
      "Epoch 46: loss=0.12709\n",
      "Epoch 47: loss=0.10474\n",
      "Epoch 48: loss=0.07082\n",
      "Epoch 49: loss=0.07382\n",
      "Epoch 50: loss=0.09312\n",
      "Epoch 51: loss=0.10166\n",
      "Epoch 52: loss=0.09902\n",
      "Epoch 53: loss=0.14680\n",
      "Epoch 54: loss=0.12228\n",
      "Epoch 55: loss=0.13735\n",
      "Epoch 56: loss=0.08625\n",
      "Epoch 57: loss=0.13030\n",
      "Epoch 58: loss=0.06324\n",
      "Epoch 59: loss=0.13576\n",
      "Epoch 60: loss=0.10192\n",
      "Epoch 61: loss=0.11503\n",
      "Epoch 62: loss=0.10787\n",
      "Epoch 63: loss=0.04976\n",
      "Epoch 64: loss=0.09334\n",
      "Epoch 65: loss=0.10761\n",
      "Epoch 66: loss=0.15067\n",
      "Epoch 67: loss=0.11900\n",
      "Epoch 68: loss=0.06377\n",
      "Epoch 69: loss=0.07832\n",
      "Epoch 70: loss=0.13099\n",
      "Epoch 71: loss=0.09968\n",
      "Epoch 72: loss=0.04617\n",
      "Epoch 73: loss=0.04907\n",
      "Epoch 74: loss=0.08067\n",
      "Epoch 75: loss=0.06093\n",
      "Epoch 76: loss=0.10594\n",
      "Epoch 77: loss=0.09418\n",
      "Epoch 78: loss=0.04719\n",
      "Epoch 79: loss=0.07163\n",
      "Epoch 80: loss=0.13374\n",
      "Epoch 81: loss=0.14031\n",
      "Epoch 82: loss=0.11208\n",
      "Epoch 83: loss=0.07170\n",
      "Epoch 84: loss=0.08084\n",
      "Epoch 85: loss=0.03083\n",
      "Epoch 86: loss=0.07549\n",
      "Epoch 87: loss=0.09049\n",
      "Epoch 88: loss=0.16396\n",
      "Epoch 89: loss=0.07000\n",
      "Epoch 90: loss=0.06957\n",
      "Epoch 91: loss=0.03292\n",
      "Epoch 92: loss=0.11920\n",
      "Epoch 93: loss=0.06002\n",
      "Epoch 94: loss=0.09265\n",
      "Epoch 95: loss=0.07733\n",
      "Epoch 96: loss=0.09676\n",
      "Epoch 97: loss=0.14580\n",
      "Epoch 98: loss=0.05279\n",
      "Epoch 99: loss=0.06503\n",
      "Epoch 100: loss=0.06908\n",
      "Epoch 101: loss=0.12412\n",
      "Epoch 102: loss=0.07947\n",
      "Epoch 103: loss=0.04939\n",
      "Epoch 104: loss=0.05021\n",
      "Epoch 105: loss=0.05818\n",
      "Epoch 106: loss=0.06476\n",
      "Epoch 107: loss=0.06118\n",
      "Epoch 108: loss=0.05435\n",
      "Epoch 109: loss=0.03455\n",
      "Epoch 110: loss=0.06911\n",
      "Epoch 111: loss=0.04312\n",
      "Epoch 112: loss=0.08049\n",
      "Epoch 113: loss=0.06114\n",
      "Epoch 114: loss=0.04982\n",
      "Epoch 115: loss=0.08266\n",
      "Epoch 116: loss=0.06208\n",
      "Epoch 117: loss=0.02098\n",
      "Epoch 118: loss=0.04754\n",
      "Epoch 119: loss=0.07461\n",
      "Epoch 120: loss=0.06195\n",
      "Epoch 121: loss=0.04882\n",
      "Epoch 122: loss=0.07101\n",
      "Epoch 123: loss=0.08799\n",
      "Epoch 124: loss=0.07906\n",
      "Epoch 125: loss=0.06843\n",
      "Epoch 126: loss=0.10345\n",
      "Epoch 127: loss=0.08809\n",
      "Epoch 128: loss=0.07186\n",
      "Epoch 129: loss=0.07728\n",
      "Epoch 130: loss=0.05944\n",
      "Epoch 131: loss=0.12432\n",
      "Epoch 132: loss=0.13937\n",
      "Epoch 133: loss=0.07149\n",
      "Epoch 134: loss=0.10080\n",
      "Epoch 135: loss=0.03217\n",
      "Epoch 136: loss=0.05323\n",
      "Epoch 137: loss=0.04411\n",
      "Epoch 138: loss=0.05462\n",
      "Epoch 139: loss=0.03688\n",
      "Epoch 140: loss=0.02093\n",
      "Epoch 141: loss=0.07075\n",
      "Epoch 142: loss=0.02738\n",
      "Epoch 143: loss=0.02524\n",
      "Epoch 144: loss=0.03873\n",
      "Epoch 145: loss=0.05346\n",
      "Epoch 146: loss=0.04288\n",
      "Epoch 147: loss=0.05185\n",
      "Epoch 148: loss=0.05037\n",
      "Epoch 149: loss=0.03231\n",
      "Epoch 150: loss=0.03019\n",
      "Epoch 151: loss=0.08740\n",
      "Epoch 152: loss=0.05604\n",
      "Epoch 153: loss=0.07137\n",
      "Epoch 154: loss=0.07396\n",
      "Epoch 155: loss=0.09953\n",
      "Epoch 156: loss=0.12280\n",
      "Epoch 157: loss=0.03050\n",
      "Epoch 158: loss=0.01540\n",
      "Epoch 159: loss=0.06970\n",
      "Epoch 160: loss=0.01764\n",
      "Epoch 161: loss=0.05877\n",
      "Epoch 162: loss=0.06264\n",
      "Epoch 163: loss=0.02648\n",
      "Epoch 164: loss=0.02980\n",
      "Epoch 165: loss=0.05958\n",
      "Epoch 166: loss=0.02034\n",
      "Epoch 167: loss=0.01480\n",
      "Epoch 168: loss=0.03113\n",
      "Epoch 169: loss=0.01065\n",
      "Epoch 170: loss=0.05684\n",
      "Epoch 171: loss=0.03052\n",
      "Epoch 172: loss=0.02337\n",
      "Epoch 173: loss=0.01700\n",
      "Epoch 174: loss=0.04731\n",
      "Epoch 175: loss=0.03587\n",
      "Epoch 176: loss=0.06901\n",
      "Epoch 177: loss=0.07910\n",
      "Epoch 178: loss=0.05909\n",
      "Epoch 179: loss=0.09781\n",
      "Epoch 180: loss=0.04990\n",
      "Epoch 181: loss=0.08601\n",
      "Epoch 182: loss=0.07412\n",
      "Epoch 183: loss=0.16075\n",
      "Epoch 184: loss=0.07243\n",
      "Epoch 185: loss=0.05558\n",
      "Epoch 186: loss=0.04826\n",
      "Epoch 187: loss=0.07371\n",
      "Epoch 188: loss=0.04470\n",
      "Epoch 189: loss=0.04215\n",
      "Epoch 190: loss=0.04885\n",
      "Epoch 191: loss=0.05368\n",
      "Epoch 192: loss=0.08307\n",
      "Epoch 193: loss=0.04315\n",
      "Epoch 194: loss=0.07108\n",
      "Epoch 195: loss=0.03700\n",
      "Epoch 196: loss=0.03710\n",
      "Epoch 197: loss=0.03537\n",
      "Epoch 198: loss=0.03729\n",
      "Epoch 199: loss=0.06729\n",
      "Epoch 200: loss=0.04246\n"
     ]
    }
   ],
   "source": [
    "loss_hist = train(x_train, y_train, lr=2e-4, nb_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 495x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3.3,2),dpi=150)\n",
    "plt.plot(loss_hist)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.950\n",
      "Test accuracy: 0.931\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: %.3f\"%(compute_classification_accuracy(x_train,y_train, batch_size=256, shuffle=True)))\n",
    "print(\"Test accuracy: %.3f\"%(compute_classification_accuracy(x_test,y_test, batch_size=256, shuffle=True)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Oct 24 2022, 16:02:16) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "59c89e211e6a7d15bcf1fda4d2617053683adc75be6d99dab9047beccd836cf8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
