{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For more details on surrogate gradient learning, please see: \n",
    "> Neftci, E.O., Mostafa, H., and Zenke, F. (2019). Surrogate Gradient Learning in Spiking Neural Networks.\n",
    "> https://arxiv.org/abs/1901.09948"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Training a spiking neural network on a simple vision dataset\n",
    "\n",
    "Friedemann Zenke (https://fzenke.net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Tutorial 2, we have seen how to train a simple multi-layer spiking neural network on the [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist). However, the spiking activity in the hidden layer was not particularly plausible in a biological sense. Here we modify the network from this previous tutorial by adding activity regularizer, which encourages solutions with sparse spiking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coarse network structure is dicated by the Fashion MNIST dataset. \n",
    "nb_inputs  = 28*28\n",
    "nb_hidden  = 100\n",
    "nb_outputs = 10\n",
    "\n",
    "time_step = 1e-2\n",
    "nb_steps  = 100\n",
    "\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "\n",
    "# Check whether a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")     \n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we load the Dataset\n",
    "root = os.path.expanduser(\"~/data/datasets/torch/mnist\")\n",
    "train_dataset = torchvision.datasets.MNIST(root, train=True, transform=None, target_transform=None, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root, train=False, transform=None, target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joshua\\AppData\\Local\\Temp\\ipykernel_17652\\1224777063.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x_train = np.array(train_dataset.data, dtype=np.float)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Temp\\ipykernel_17652\\1224777063.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x_test = np.array(test_dataset.data, dtype=np.float)\n"
     ]
    }
   ],
   "source": [
    "# Standardize data\n",
    "# x_train = torch.tensor(train_dataset.train_data, device=device, dtype=dtype)\n",
    "x_train = np.array(train_dataset.data, dtype=np.float)\n",
    "x_train = x_train.reshape(x_train.shape[0],-1)/255\n",
    "# x_test = torch.tensor(test_dataset.test_data, device=device, dtype=dtype)\n",
    "x_test = np.array(test_dataset.data, dtype=np.float)\n",
    "x_test = x_test.reshape(x_test.shape[0],-1)/255\n",
    "\n",
    "# y_train = torch.tensor(train_dataset.train_labels, device=device, dtype=dtype)\n",
    "# y_test  = torch.tensor(test_dataset.test_labels, device=device, dtype=dtype)\n",
    "y_train = np.array(train_dataset.targets, dtype=np.int64)\n",
    "y_test  = np.array(test_dataset.targets, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we plot one of the raw data points as an example\n",
    "data_id = 2\n",
    "plt.imshow(x_train[data_id].reshape(28,28), cmap=plt.cm.gray_r)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are working with spiking neural networks, we ideally want to use a temporal code to make use of spike timing. To that end, we will use a spike latency code to feed spikes to our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current2firing_time(x, tau=20, thr=0.3, tmax=1.0, epsilon=1e-7):\n",
    "    \"\"\" Computes first firing time latency for a current input x assuming the charge time of a current based LIF neuron.\n",
    "\n",
    "    Args:\n",
    "    x -- The \"current\" values\n",
    "\n",
    "    Keyword args:\n",
    "    tau -- The membrane time constant of the LIF neuron to be charged\n",
    "    thr -- The firing threshold value \n",
    "    tmax -- The maximum time returned \n",
    "    epsilon -- A generic (small) epsilon > 0\n",
    "\n",
    "    Returns:\n",
    "    Time to first spike for each \"current\" x\n",
    "    \"\"\"\n",
    "    idx = x<thr\n",
    "    x = np.clip(x,thr+epsilon,1e9)\n",
    "    T = tau*np.log(x/(x-thr))\n",
    "    T[idx] = tmax\n",
    "    return T\n",
    "\n",
    "def spike_fn(x):\n",
    "    out = torch.zeros_like(x)\n",
    "    out[x > 0] = 1.0\n",
    "    return out\n",
    "        \n",
    "def sparse_data_generator(X, y, batch_size, nb_steps, nb_units, shuffle=True ):\n",
    "    \"\"\" This generator takes datasets in analog format and generates spiking network input as sparse tensors. \n",
    "\n",
    "    Args:\n",
    "        X: The data ( sample x event x 2 ) the last dim holds (time,neuron) tuples\n",
    "        y: The labels\n",
    "    \"\"\"\n",
    "\n",
    "    labels_ = np.array(y,dtype=np.int64)\n",
    "    number_of_batches = len(X)//batch_size\n",
    "    sample_index = np.arange(len(X))\n",
    "\n",
    "    # compute discrete firing times\n",
    "    tau_eff = 20e-3/time_step\n",
    "    firing_times = np.array(current2firing_time(X, tau=tau_eff, tmax=nb_steps), dtype=np.int64)\n",
    "    unit_numbers = np.arange(nb_units)\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "\n",
    "    total_batch_count = 0\n",
    "    counter = 0\n",
    "    while counter<number_of_batches:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "\n",
    "        coo = [ [] for i in range(3) ]\n",
    "        for bc,idx in enumerate(batch_index):\n",
    "            \n",
    "            batch = [bc for _ in range(len(times))]\n",
    "            coo[0].extend(batch)\n",
    "            \n",
    "\n",
    "        i = torch.LongTensor(coo).to(device)\n",
    "        v = torch.FloatTensor(np.ones(len(coo[0]))).to(device)\n",
    "    \n",
    "        X_batch = torch.sparse.FloatTensor(i, v, torch.Size([batch_size,nb_steps,nb_units])).to(device)\n",
    "        y_batch = torch.tensor(labels_[batch_index],device=device)\n",
    "\n",
    "        yield X_batch.to(device=device), y_batch.to(device=device)\n",
    "\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_image(image, scale, time_step):\n",
    "    scaled_image = image*scale\n",
    "    for i,prob in enumerate(scaled_image):\n",
    "        if (prob > 1):\n",
    "            new_prob = 1\n",
    "            scaled_image[i] = new_prob\n",
    "    rate_of_scaled_image = scaled_image/time_step\n",
    "    average_rate = torch.mean(rate_of_scaled_image)\n",
    "    return scaled_image, average_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images2spike(x, y, batch_size, shuffle, **kwargs):  \n",
    "    '''Converts images to spike trains'''\n",
    "    labels_ = np.array(y,dtype=np.int64)\n",
    "    number_of_batches = len(x)//batch_size\n",
    "    sample_index = np.arange(len(x))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "\n",
    "    total_batch_count = 0\n",
    "    counter = 0\n",
    "\n",
    "    batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "    while counter < number_of_batches:\n",
    "        x_batch = torch.empty((len(x[batch_index]), nb_steps, nb_inputs)).to(device)\n",
    "        for i, image in enumerate(x[batch_index]):\n",
    "            tensor_image = torch.Tensor(image) # probabilities tensor\n",
    "            zero_image = torch.zeros(tensor_image.shape)\n",
    "            spike_train = torch.empty((nb_steps, nb_inputs))\n",
    "            for t in range(nb_steps):\n",
    "                spike_t = torch.bernoulli(tensor_image)\n",
    "                spike_train[t] = spike_t\n",
    "            x_batch[i] = spike_train\n",
    "        y_batch = torch.tensor(labels_[batch_index],device=device) \n",
    "\n",
    "        yield x_batch,  y_batch\n",
    "\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup of the spiking network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "\n",
    "alpha   = float(np.exp(-time_step/tau_syn))\n",
    "beta    = float(np.exp(-time_step/tau_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init done\n"
     ]
    }
   ],
   "source": [
    "weight_scale = 0.002\n",
    "\n",
    "w1 = torch.empty((nb_inputs, nb_hidden),  device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w1, mean=0.0, std=weight_scale)\n",
    "\n",
    "w2 = torch.empty((nb_hidden, nb_outputs), device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w2, mean=0.0, std=weight_scale)\n",
    "\n",
    "print(\"init done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_voltage_traces(mem, spk=None, dim=(3,5), spike_height=5):\n",
    "    gs=GridSpec(*dim)\n",
    "    if spk is not None:\n",
    "        dat = 1.0*mem\n",
    "        dat[spk>0.0] = spike_height\n",
    "        dat = dat.detach().cpu().numpy()\n",
    "    else:\n",
    "        dat = mem.detach().cpu().numpy()\n",
    "    for i in range(np.prod(dim)):\n",
    "        if i==0: a0=ax=plt.subplot(gs[i])\n",
    "        else: ax=plt.subplot(gs[i],sharey=a0)\n",
    "        ax.plot(dat[i])\n",
    "        ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurrGradSpike(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Here we implement our spiking nonlinearity which also implements \n",
    "    the surrogate gradient. By subclassing torch.autograd.Function, \n",
    "    we will be able to use all of PyTorch's autograd functionality.\n",
    "    Here we use the normalized negative part of a fast sigmoid \n",
    "    as this was done in Zenke & Ganguli (2018).\n",
    "    \"\"\"\n",
    "    \n",
    "    scale = 100.0 # controls steepness of surrogate gradient\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we compute a step function of the input Tensor\n",
    "        and return it. ctx is a context object that we use to stash information which \n",
    "        we need to later backpropagate our error signals. To achieve this we use the \n",
    "        ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        out = torch.zeros_like(input)\n",
    "        out[input > 0] = 1.0\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor we need to compute the \n",
    "        surrogate gradient of the loss with respect to the input. \n",
    "        Here we use the normalized negative part of a fast sigmoid \n",
    "        as this was done in Zenke & Ganguli (2018).\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad = grad_input/(SurrGradSpike.scale*torch.abs(input)+1.0)**2\n",
    "        return grad\n",
    "    \n",
    "# here we overwrite our naive spike function by the \"SurrGradSpike\" nonlinearity which implements a surrogate gradient\n",
    "spike_fn  = SurrGradSpike.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_snn(inputs):\n",
    "    h1 = torch.einsum(\"abc,cd->abd\", (inputs, w1))\n",
    "    syn = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "    mem = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "\n",
    "    mem_rec = []\n",
    "    spk_rec = []\n",
    "\n",
    "    # Compute hidden layer activity\n",
    "    for t in range(nb_steps):\n",
    "        mthr = mem-1.0\n",
    "        out = spike_fn(mthr)\n",
    "        rst = out.detach() # We do not want to backprop through the reset\n",
    "\n",
    "        new_syn = alpha*syn +h1[:,t]\n",
    "        new_mem = (beta*mem +syn)*(1.0-rst)\n",
    "\n",
    "        mem_rec.append(mem)\n",
    "        spk_rec.append(out)\n",
    "        \n",
    "        mem = new_mem\n",
    "        syn = new_syn\n",
    "\n",
    "    mem_rec = torch.stack(mem_rec,dim=1)\n",
    "    spk_rec = torch.stack(spk_rec,dim=1)\n",
    "\n",
    "    # Readout layer\n",
    "    h2= torch.einsum(\"abc,cd->abd\", (spk_rec, w2))\n",
    "    flt = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out_rec = [out]\n",
    "    spk_rec2 = []\n",
    "    for t in range(nb_steps):\n",
    "        mthr = out-1.0\n",
    "        output = spike_fn(mthr)\n",
    "        rst = output.detach() # We do not want to backprop through the reset\n",
    "\n",
    "        new_flt = alpha*flt +h2[:,t]\n",
    "        new_out = (beta*out +flt)*(1.0-rst)\n",
    "\n",
    "        flt = new_flt\n",
    "        out = new_out\n",
    "\n",
    "        out_rec.append(out) # membrane potential\n",
    "        spk_rec2.append(output) # spike train\n",
    "\n",
    "    out_rec = torch.stack(out_rec,dim=1)\n",
    "    spk_rec2 = torch.stack(spk_rec2, dim=1)\n",
    "\n",
    "    return spk_rec2,  spk_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_data, y_data, scale=1, lr=1e-3, nb_epochs=10):\n",
    "    params = [w1,w2]\n",
    "    optimizer = torch.optim.Adamax(params, lr=lr, betas=(0.9,0.999))\n",
    "\n",
    "    log_softmax_fn = nn.LogSoftmax(dim=1)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    \n",
    "    loss_hist = []\n",
    "    for e in range(nb_epochs):\n",
    "        local_loss = []\n",
    "        for x_local, y_local in images2spike(x_data, y_data, batch_size, shuffle=True):\n",
    "            output, spks = run_snn(x_local)\n",
    "            spike_count =torch.sum(output,1)\n",
    "            mean_firing_rate = spike_count/(nb_steps*time_step)\n",
    "\n",
    "            log_p_y = log_softmax_fn(mean_firing_rate)\n",
    "            \n",
    "            # Here we set up our regularizer loss\n",
    "            # The strength paramters here are merely a guess and there should be ample room for improvement by\n",
    "            # tuning these paramters.\n",
    "            reg_loss = 1e-6*torch.sum(spks) # L1 loss on total number of spikes\n",
    "            reg_loss += 1e-7*torch.mean(torch.sum(torch.sum(spks,dim=0),dim=0)**2) # L2 loss on spikes per neuron\n",
    "\n",
    "            # Here we combine supervised loss and the regularizer\n",
    "            loss_val = loss_fn(log_p_y, y_local) \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "            local_loss.append(loss_val.item())\n",
    "        mean_loss = np.mean(local_loss)\n",
    "        print(\"Epoch %i: loss=%.5f\"%(e+1,mean_loss))\n",
    "        loss_hist.append(mean_loss)\n",
    "        \n",
    "    return loss_hist\n",
    "        \n",
    "        \n",
    "def compute_classification_accuracy(x_data, y_data, batch_size, shuffle, **kwargs):\n",
    "    \"\"\" Computes classification accuracy on supplied data in batches. \"\"\"\n",
    "    accs = []\n",
    "    for x_local, y_local in images2spike(x_data, y_data, batch_size, shuffle=True, **kwargs):\n",
    "        output, _ = run_snn(x_local)\n",
    "        spike_count =torch.sum(output,1)\n",
    "        mean_firing_rate = spike_count/(nb_steps*time_step)\n",
    "        _, am = torch.max(mean_firing_rate, 1)\n",
    "        tmp = np.mean((y_local==am).detach().cpu().numpy()) # compare to labels\n",
    "        accs.append(tmp)\n",
    "    return np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=2.30258\n",
      "Epoch 2: loss=2.22629\n",
      "Epoch 3: loss=1.33313\n",
      "Epoch 4: loss=0.67650\n",
      "Epoch 5: loss=0.46182\n",
      "Epoch 6: loss=0.25788\n",
      "Epoch 7: loss=0.55606\n",
      "Epoch 8: loss=0.34723\n",
      "Epoch 9: loss=0.38826\n",
      "Epoch 10: loss=0.38795\n",
      "Epoch 11: loss=0.31735\n",
      "Epoch 12: loss=0.23162\n",
      "Epoch 13: loss=0.44809\n",
      "Epoch 14: loss=0.21956\n",
      "Epoch 15: loss=0.20158\n",
      "Epoch 16: loss=0.37451\n",
      "Epoch 17: loss=0.23768\n",
      "Epoch 18: loss=0.09604\n",
      "Epoch 19: loss=0.25917\n",
      "Epoch 20: loss=0.13020\n",
      "Epoch 21: loss=0.17770\n",
      "Epoch 22: loss=0.24278\n",
      "Epoch 23: loss=0.13993\n",
      "Epoch 24: loss=0.10239\n",
      "Epoch 25: loss=0.14942\n",
      "Epoch 26: loss=0.16855\n",
      "Epoch 27: loss=0.15541\n",
      "Epoch 28: loss=0.12681\n",
      "Epoch 29: loss=0.15874\n",
      "Epoch 30: loss=0.17141\n",
      "Epoch 31: loss=0.18729\n",
      "Epoch 32: loss=0.14176\n",
      "Epoch 33: loss=0.09747\n",
      "Epoch 34: loss=0.07305\n",
      "Epoch 35: loss=0.13525\n",
      "Epoch 36: loss=0.10016\n",
      "Epoch 37: loss=0.17538\n",
      "Epoch 38: loss=0.08611\n",
      "Epoch 39: loss=0.07055\n",
      "Epoch 40: loss=0.08739\n",
      "Epoch 41: loss=0.09552\n",
      "Epoch 42: loss=0.10139\n",
      "Epoch 43: loss=0.09615\n",
      "Epoch 44: loss=0.10027\n",
      "Epoch 45: loss=0.07105\n",
      "Epoch 46: loss=0.10586\n",
      "Epoch 47: loss=0.10304\n",
      "Epoch 48: loss=0.07253\n",
      "Epoch 49: loss=0.07436\n",
      "Epoch 50: loss=0.03990\n",
      "Epoch 51: loss=0.10752\n",
      "Epoch 52: loss=0.14621\n",
      "Epoch 53: loss=0.11671\n",
      "Epoch 54: loss=0.09783\n",
      "Epoch 55: loss=0.06513\n",
      "Epoch 56: loss=0.16573\n",
      "Epoch 57: loss=0.14460\n",
      "Epoch 58: loss=0.10202\n",
      "Epoch 59: loss=0.04640\n",
      "Epoch 60: loss=0.13374\n",
      "Epoch 61: loss=0.06216\n",
      "Epoch 62: loss=0.13917\n",
      "Epoch 63: loss=0.06445\n",
      "Epoch 64: loss=0.06273\n",
      "Epoch 65: loss=0.04704\n",
      "Epoch 66: loss=0.09732\n",
      "Epoch 67: loss=0.04616\n",
      "Epoch 68: loss=0.04435\n",
      "Epoch 69: loss=0.06283\n",
      "Epoch 70: loss=0.11102\n",
      "Epoch 71: loss=0.03152\n",
      "Epoch 72: loss=0.09554\n",
      "Epoch 73: loss=0.10899\n",
      "Epoch 74: loss=0.05959\n",
      "Epoch 75: loss=0.03492\n",
      "Epoch 76: loss=0.06651\n",
      "Epoch 77: loss=0.13206\n",
      "Epoch 78: loss=0.07204\n",
      "Epoch 79: loss=0.05597\n",
      "Epoch 80: loss=0.04281\n",
      "Epoch 81: loss=0.06575\n",
      "Epoch 82: loss=0.03054\n",
      "Epoch 83: loss=0.03202\n",
      "Epoch 84: loss=0.02118\n",
      "Epoch 85: loss=0.04108\n",
      "Epoch 86: loss=0.07758\n",
      "Epoch 87: loss=0.05189\n",
      "Epoch 88: loss=0.11453\n",
      "Epoch 89: loss=0.05361\n",
      "Epoch 90: loss=0.04687\n",
      "Epoch 91: loss=0.05625\n",
      "Epoch 92: loss=0.04157\n",
      "Epoch 93: loss=0.03457\n",
      "Epoch 94: loss=0.05087\n",
      "Epoch 95: loss=0.03689\n",
      "Epoch 96: loss=0.04449\n",
      "Epoch 97: loss=0.05459\n",
      "Epoch 98: loss=0.06587\n",
      "Epoch 99: loss=0.05538\n",
      "Epoch 100: loss=0.06158\n"
     ]
    }
   ],
   "source": [
    "loss_hist = train(x_train, y_train, lr=2e-4, nb_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 495x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3.3,2),dpi=150)\n",
    "plt.plot(loss_hist)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.925\n",
      "Test accuracy: 0.930\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: %.3f\"%(compute_classification_accuracy(x_train,y_train, batch_size=256, shuffle=True)))\n",
    "print(\"Test accuracy: %.3f\"%(compute_classification_accuracy(x_test,y_test, batch_size=256, shuffle=True)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Oct 24 2022, 16:02:16) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "59c89e211e6a7d15bcf1fda4d2617053683adc75be6d99dab9047beccd836cf8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
