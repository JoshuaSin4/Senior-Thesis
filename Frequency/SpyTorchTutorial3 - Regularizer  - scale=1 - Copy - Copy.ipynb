{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For more details on surrogate gradient learning, please see: \n",
    "> Neftci, E.O., Mostafa, H., and Zenke, F. (2019). Surrogate Gradient Learning in Spiking Neural Networks.\n",
    "> https://arxiv.org/abs/1901.09948"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Training a spiking neural network on a simple vision dataset\n",
    "\n",
    "Friedemann Zenke (https://fzenke.net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Tutorial 2, we have seen how to train a simple multi-layer spiking neural network on the [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist). However, the spiking activity in the hidden layer was not particularly plausible in a biological sense. Here we modify the network from this previous tutorial by adding activity regularizer, which encourages solutions with sparse spiking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coarse network structure is dicated by the Fashion MNIST dataset. \n",
    "nb_inputs  = 28*28\n",
    "nb_hidden  = 100\n",
    "nb_outputs = 10\n",
    "\n",
    "time_step = 1e-2\n",
    "nb_steps  = 100\n",
    "\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "\n",
    "# Check whether a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")     \n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we load the Dataset\n",
    "root = os.path.expanduser(\"~/data/datasets/torch/mnist\")\n",
    "train_dataset = torchvision.datasets.MNIST(root, train=True, transform=None, target_transform=None, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root, train=False, transform=None, target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joshua\\AppData\\Local\\Temp\\ipykernel_19964\\1224777063.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x_train = np.array(train_dataset.data, dtype=np.float)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Temp\\ipykernel_19964\\1224777063.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x_test = np.array(test_dataset.data, dtype=np.float)\n"
     ]
    }
   ],
   "source": [
    "# Standardize data\n",
    "# x_train = torch.tensor(train_dataset.train_data, device=device, dtype=dtype)\n",
    "x_train = np.array(train_dataset.data, dtype=np.float)\n",
    "x_train = x_train.reshape(x_train.shape[0],-1)/255\n",
    "# x_test = torch.tensor(test_dataset.test_data, device=device, dtype=dtype)\n",
    "x_test = np.array(test_dataset.data, dtype=np.float)\n",
    "x_test = x_test.reshape(x_test.shape[0],-1)/255\n",
    "\n",
    "# y_train = torch.tensor(train_dataset.train_labels, device=device, dtype=dtype)\n",
    "# y_test  = torch.tensor(test_dataset.test_labels, device=device, dtype=dtype)\n",
    "y_train = np.array(train_dataset.targets, dtype=np.int64)\n",
    "y_test  = np.array(test_dataset.targets, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we plot one of the raw data points as an example\n",
    "data_id = 2\n",
    "plt.imshow(x_train[data_id].reshape(28,28), cmap=plt.cm.gray_r)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are working with spiking neural networks, we ideally want to use a temporal code to make use of spike timing. To that end, we will use a spike latency code to feed spikes to our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current2firing_time(x, tau=20, thr=0.3, tmax=1.0, epsilon=1e-7):\n",
    "    \"\"\" Computes first firing time latency for a current input x assuming the charge time of a current based LIF neuron.\n",
    "\n",
    "    Args:\n",
    "    x -- The \"current\" values\n",
    "\n",
    "    Keyword args:\n",
    "    tau -- The membrane time constant of the LIF neuron to be charged\n",
    "    thr -- The firing threshold value \n",
    "    tmax -- The maximum time returned \n",
    "    epsilon -- A generic (small) epsilon > 0\n",
    "\n",
    "    Returns:\n",
    "    Time to first spike for each \"current\" x\n",
    "    \"\"\"\n",
    "    idx = x<thr\n",
    "    x = np.clip(x,thr+epsilon,1e9)\n",
    "    T = tau*np.log(x/(x-thr))\n",
    "    T[idx] = tmax\n",
    "    return T\n",
    "\n",
    "def spike_fn(x):\n",
    "    out = torch.zeros_like(x)\n",
    "    out[x > 0] = 1.0\n",
    "    return out\n",
    "        \n",
    "def sparse_data_generator(X, y, batch_size, nb_steps, nb_units, shuffle=True ):\n",
    "    \"\"\" This generator takes datasets in analog format and generates spiking network input as sparse tensors. \n",
    "\n",
    "    Args:\n",
    "        X: The data ( sample x event x 2 ) the last dim holds (time,neuron) tuples\n",
    "        y: The labels\n",
    "    \"\"\"\n",
    "\n",
    "    labels_ = np.array(y,dtype=np.int64)\n",
    "    number_of_batches = len(X)//batch_size\n",
    "    sample_index = np.arange(len(X))\n",
    "\n",
    "    # compute discrete firing times\n",
    "    tau_eff = 20e-3/time_step\n",
    "    firing_times = np.array(current2firing_time(X, tau=tau_eff, tmax=nb_steps), dtype=np.int64)\n",
    "    unit_numbers = np.arange(nb_units)\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "\n",
    "    total_batch_count = 0\n",
    "    counter = 0\n",
    "    while counter<number_of_batches:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "\n",
    "        coo = [ [] for i in range(3) ]\n",
    "        for bc,idx in enumerate(batch_index):\n",
    "            \n",
    "            batch = [bc for _ in range(len(times))]\n",
    "            coo[0].extend(batch)\n",
    "            \n",
    "\n",
    "        i = torch.LongTensor(coo).to(device)\n",
    "        v = torch.FloatTensor(np.ones(len(coo[0]))).to(device)\n",
    "    \n",
    "        X_batch = torch.sparse.FloatTensor(i, v, torch.Size([batch_size,nb_steps,nb_units])).to(device)\n",
    "        y_batch = torch.tensor(labels_[batch_index],device=device)\n",
    "\n",
    "        yield X_batch.to(device=device), y_batch.to(device=device)\n",
    "\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_image(image, scale, time_step):\n",
    "    scaled_image = image*scale\n",
    "    for i,prob in enumerate(scaled_image):\n",
    "        if (prob > 1):\n",
    "            new_prob = 1\n",
    "            scaled_image[i] = new_prob\n",
    "    rate_of_scaled_image = scaled_image/time_step\n",
    "    average_rate = torch.mean(rate_of_scaled_image)\n",
    "    return scaled_image, average_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images2spike(x, y, batch_size, shuffle, **kwargs):  \n",
    "    '''Converts images to spike trains'''\n",
    "    labels_ = np.array(y,dtype=np.int64)\n",
    "    number_of_batches = len(x)//batch_size\n",
    "    sample_index = np.arange(len(x))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "\n",
    "    total_batch_count = 0\n",
    "    counter = 0\n",
    "\n",
    "    batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "    while counter < number_of_batches:\n",
    "        x_batch = torch.empty((len(x[batch_index]), nb_steps, nb_inputs)).to(device)\n",
    "        for i, image in enumerate(x[batch_index]):\n",
    "            tensor_image = torch.Tensor(image) # probabilities tensor\n",
    "            zero_image = torch.zeros(tensor_image.shape)\n",
    "            spike_train = torch.empty((nb_steps, nb_inputs))\n",
    "            for t in range(nb_steps):\n",
    "                spike_t = torch.bernoulli(tensor_image)\n",
    "                spike_train[t] = spike_t\n",
    "            x_batch[i] = spike_train\n",
    "        y_batch = torch.tensor(labels_[batch_index],device=device) \n",
    "\n",
    "        yield x_batch,  y_batch\n",
    "\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup of the spiking network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "\n",
    "alpha   = float(np.exp(-time_step/tau_syn))\n",
    "beta    = float(np.exp(-time_step/tau_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init done\n"
     ]
    }
   ],
   "source": [
    "weight_scale = 0.1\n",
    "\n",
    "w1 = torch.empty((nb_inputs, nb_hidden),  device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w1, mean=0.0, std=weight_scale/np.sqrt(nb_inputs))\n",
    "\n",
    "w2 = torch.empty((nb_hidden, nb_outputs), device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w2, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))\n",
    "\n",
    "print(\"init done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_voltage_traces(mem, spk=None, dim=(3,5), spike_height=5):\n",
    "    gs=GridSpec(*dim)\n",
    "    if spk is not None:\n",
    "        dat = 1.0*mem\n",
    "        dat[spk>0.0] = spike_height\n",
    "        dat = dat.detach().cpu().numpy()\n",
    "    else:\n",
    "        dat = mem.detach().cpu().numpy()\n",
    "    for i in range(np.prod(dim)):\n",
    "        if i==0: a0=ax=plt.subplot(gs[i])\n",
    "        else: ax=plt.subplot(gs[i],sharey=a0)\n",
    "        ax.plot(dat[i])\n",
    "        ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurrGradSpike(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Here we implement our spiking nonlinearity which also implements \n",
    "    the surrogate gradient. By subclassing torch.autograd.Function, \n",
    "    we will be able to use all of PyTorch's autograd functionality.\n",
    "    Here we use the normalized negative part of a fast sigmoid \n",
    "    as this was done in Zenke & Ganguli (2018).\n",
    "    \"\"\"\n",
    "    \n",
    "    scale = 100.0 # controls steepness of surrogate gradient\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we compute a step function of the input Tensor\n",
    "        and return it. ctx is a context object that we use to stash information which \n",
    "        we need to later backpropagate our error signals. To achieve this we use the \n",
    "        ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        out = torch.zeros_like(input)\n",
    "        out[input > 0] = 1.0\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor we need to compute the \n",
    "        surrogate gradient of the loss with respect to the input. \n",
    "        Here we use the normalized negative part of a fast sigmoid \n",
    "        as this was done in Zenke & Ganguli (2018).\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad = grad_input/(SurrGradSpike.scale*torch.abs(input)+1.0)**2\n",
    "        return grad\n",
    "    \n",
    "# here we overwrite our naive spike function by the \"SurrGradSpike\" nonlinearity which implements a surrogate gradient\n",
    "spike_fn  = SurrGradSpike.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_snn(inputs):\n",
    "    h1 = torch.einsum(\"abc,cd->abd\", (inputs, w1))\n",
    "    syn = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "    mem = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "\n",
    "    mem_rec = []\n",
    "    spk_rec = []\n",
    "\n",
    "    # Compute hidden layer activity\n",
    "    for t in range(nb_steps):\n",
    "        mthr = mem-1.0\n",
    "        out = spike_fn(mthr)\n",
    "        rst = out.detach() # We do not want to backprop through the reset\n",
    "\n",
    "        new_syn = alpha*syn +h1[:,t]\n",
    "        new_mem = (beta*mem +syn)*(1.0-rst)\n",
    "\n",
    "        mem_rec.append(mem)\n",
    "        spk_rec.append(out)\n",
    "        \n",
    "        mem = new_mem\n",
    "        syn = new_syn\n",
    "\n",
    "    mem_rec = torch.stack(mem_rec,dim=1)\n",
    "    spk_rec = torch.stack(spk_rec,dim=1)\n",
    "\n",
    "    # Readout layer\n",
    "    h2= torch.einsum(\"abc,cd->abd\", (spk_rec, w2))\n",
    "    flt = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out_rec = [out]\n",
    "    spk_rec2 = []\n",
    "    for t in range(nb_steps):\n",
    "        mthr = out-1.0\n",
    "        output = spike_fn(mthr)\n",
    "        rst = output.detach() # We do not want to backprop through the reset\n",
    "\n",
    "        new_flt = alpha*flt +h2[:,t]\n",
    "        new_out = (beta*out +flt)*(1.0-rst)\n",
    "\n",
    "        flt = new_flt\n",
    "        out = new_out\n",
    "\n",
    "        out_rec.append(out) # membrane potential\n",
    "        spk_rec2.append(output) # spike train\n",
    "\n",
    "    out_rec = torch.stack(out_rec,dim=1)\n",
    "    spk_rec2 = torch.stack(spk_rec2, dim=1)\n",
    "\n",
    "    return spk_rec2,  spk_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_data, y_data, scale=1, lr=1e-3, nb_epochs=10):\n",
    "    params = [w1,w2]\n",
    "    optimizer = torch.optim.Adamax(params, lr=lr, betas=(0.9,0.999))\n",
    "\n",
    "    log_softmax_fn = nn.LogSoftmax(dim=1)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    \n",
    "    loss_hist = []\n",
    "    for e in range(nb_epochs):\n",
    "        local_loss = []\n",
    "        for x_local, y_local in images2spike(x_data, y_data, batch_size, shuffle=True):\n",
    "            output, spks = run_snn(x_local)\n",
    "            spike_count =torch.sum(output,1)\n",
    "            mean_firing_rate = spike_count/(nb_steps*time_step)\n",
    "\n",
    "            log_p_y = log_softmax_fn(mean_firing_rate)\n",
    "            \n",
    "            # Here we set up our regularizer loss\n",
    "            # The strength paramters here are merely a guess and there should be ample room for improvement by\n",
    "            # tuning these paramters.\n",
    "            reg_loss = 1e-7*torch.sum(spks) # L1 loss on total number of spikes\n",
    "            reg_loss += 1e-8*torch.mean(torch.sum(torch.sum(spks,dim=0),dim=0)**2) # L2 loss on spikes per neuron\n",
    "\n",
    "            # Here we combine supervised loss and the regularizer\n",
    "            loss_val = loss_fn(log_p_y, y_local) \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "            local_loss.append(loss_val.item())\n",
    "        mean_loss = np.mean(local_loss)\n",
    "        print(\"Epoch %i: loss=%.5f\"%(e+1,mean_loss))\n",
    "        loss_hist.append(mean_loss)\n",
    "        \n",
    "    return loss_hist\n",
    "        \n",
    "        \n",
    "def compute_classification_accuracy(x_data, y_data, batch_size, shuffle, **kwargs):\n",
    "    \"\"\" Computes classification accuracy on supplied data in batches. \"\"\"\n",
    "    accs = []\n",
    "    for x_local, y_local in images2spike(x_data, y_data, batch_size, shuffle=True, **kwargs):\n",
    "        output, _ = run_snn(x_local)\n",
    "        spike_count =torch.sum(output,1)\n",
    "        mean_firing_rate = spike_count/(nb_steps*time_step)\n",
    "        _, am = torch.max(mean_firing_rate, 1)\n",
    "        tmp = np.mean((y_local==am).detach().cpu().numpy()) # compare to labels\n",
    "        accs.append(tmp)\n",
    "    return np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=1.61353\n",
      "Epoch 2: loss=0.93821\n",
      "Epoch 3: loss=0.79675\n",
      "Epoch 4: loss=0.54973\n",
      "Epoch 5: loss=0.43871\n",
      "Epoch 6: loss=0.19275\n",
      "Epoch 7: loss=0.35730\n",
      "Epoch 8: loss=0.30097\n",
      "Epoch 9: loss=0.36140\n",
      "Epoch 10: loss=0.27961\n",
      "Epoch 11: loss=0.46934\n",
      "Epoch 12: loss=0.26050\n",
      "Epoch 13: loss=0.22666\n",
      "Epoch 14: loss=0.23701\n",
      "Epoch 15: loss=0.21017\n",
      "Epoch 16: loss=0.13280\n",
      "Epoch 17: loss=0.22181\n",
      "Epoch 18: loss=0.17511\n",
      "Epoch 19: loss=0.31872\n",
      "Epoch 20: loss=0.23823\n",
      "Epoch 21: loss=0.26905\n",
      "Epoch 22: loss=0.24717\n",
      "Epoch 23: loss=0.18752\n",
      "Epoch 24: loss=0.24492\n",
      "Epoch 25: loss=0.26841\n",
      "Epoch 26: loss=0.18531\n",
      "Epoch 27: loss=0.15589\n",
      "Epoch 28: loss=0.25649\n",
      "Epoch 29: loss=0.11155\n",
      "Epoch 30: loss=0.19734\n",
      "Epoch 31: loss=0.29908\n",
      "Epoch 32: loss=0.15005\n",
      "Epoch 33: loss=0.11413\n",
      "Epoch 34: loss=0.21921\n",
      "Epoch 35: loss=0.24102\n",
      "Epoch 36: loss=0.17562\n",
      "Epoch 37: loss=0.22846\n",
      "Epoch 38: loss=0.14756\n",
      "Epoch 39: loss=0.17206\n",
      "Epoch 40: loss=0.16758\n",
      "Epoch 41: loss=0.21900\n",
      "Epoch 42: loss=0.18181\n",
      "Epoch 43: loss=0.12074\n",
      "Epoch 44: loss=0.22207\n",
      "Epoch 45: loss=0.18288\n",
      "Epoch 46: loss=0.15324\n",
      "Epoch 47: loss=0.17984\n",
      "Epoch 48: loss=0.11400\n",
      "Epoch 49: loss=0.17365\n",
      "Epoch 50: loss=0.12825\n",
      "Epoch 51: loss=0.15490\n",
      "Epoch 52: loss=0.13210\n",
      "Epoch 53: loss=0.10020\n",
      "Epoch 54: loss=0.11565\n",
      "Epoch 55: loss=0.17001\n",
      "Epoch 56: loss=0.18099\n",
      "Epoch 57: loss=0.09673\n",
      "Epoch 58: loss=0.15695\n",
      "Epoch 59: loss=0.12658\n",
      "Epoch 60: loss=0.10034\n",
      "Epoch 61: loss=0.09011\n",
      "Epoch 62: loss=0.11866\n",
      "Epoch 63: loss=0.16718\n",
      "Epoch 64: loss=0.04280\n",
      "Epoch 65: loss=0.13335\n",
      "Epoch 66: loss=0.11244\n",
      "Epoch 67: loss=0.12429\n",
      "Epoch 68: loss=0.10245\n",
      "Epoch 69: loss=0.09994\n",
      "Epoch 70: loss=0.07479\n",
      "Epoch 71: loss=0.10421\n",
      "Epoch 72: loss=0.11721\n",
      "Epoch 73: loss=0.13187\n",
      "Epoch 74: loss=0.08109\n",
      "Epoch 75: loss=0.10112\n",
      "Epoch 76: loss=0.10061\n",
      "Epoch 77: loss=0.21995\n",
      "Epoch 78: loss=0.10899\n",
      "Epoch 79: loss=0.08034\n",
      "Epoch 80: loss=0.10903\n",
      "Epoch 81: loss=0.09073\n",
      "Epoch 82: loss=0.08179\n",
      "Epoch 83: loss=0.07259\n",
      "Epoch 84: loss=0.10621\n",
      "Epoch 85: loss=0.11921\n",
      "Epoch 86: loss=0.12195\n",
      "Epoch 87: loss=0.03743\n",
      "Epoch 88: loss=0.05512\n",
      "Epoch 89: loss=0.11407\n",
      "Epoch 90: loss=0.16719\n",
      "Epoch 91: loss=0.07548\n",
      "Epoch 92: loss=0.10995\n",
      "Epoch 93: loss=0.05549\n",
      "Epoch 94: loss=0.05985\n",
      "Epoch 95: loss=0.08449\n",
      "Epoch 96: loss=0.04022\n",
      "Epoch 97: loss=0.08473\n",
      "Epoch 98: loss=0.11953\n",
      "Epoch 99: loss=0.09410\n",
      "Epoch 100: loss=0.09849\n",
      "Epoch 101: loss=0.05184\n",
      "Epoch 102: loss=0.05304\n",
      "Epoch 103: loss=0.05060\n",
      "Epoch 104: loss=0.07646\n",
      "Epoch 105: loss=0.05029\n",
      "Epoch 106: loss=0.07774\n",
      "Epoch 107: loss=0.03603\n",
      "Epoch 108: loss=0.07267\n",
      "Epoch 109: loss=0.09173\n",
      "Epoch 110: loss=0.12252\n",
      "Epoch 111: loss=0.15427\n",
      "Epoch 112: loss=0.11678\n",
      "Epoch 113: loss=0.03862\n",
      "Epoch 114: loss=0.07910\n",
      "Epoch 115: loss=0.06144\n",
      "Epoch 116: loss=0.08217\n",
      "Epoch 117: loss=0.14448\n",
      "Epoch 118: loss=0.07931\n",
      "Epoch 119: loss=0.07873\n",
      "Epoch 120: loss=0.06263\n",
      "Epoch 121: loss=0.07982\n",
      "Epoch 122: loss=0.13401\n",
      "Epoch 123: loss=0.05516\n",
      "Epoch 124: loss=0.03236\n",
      "Epoch 125: loss=0.08155\n",
      "Epoch 126: loss=0.07583\n",
      "Epoch 127: loss=0.04695\n",
      "Epoch 128: loss=0.04777\n",
      "Epoch 129: loss=0.09566\n",
      "Epoch 130: loss=0.10446\n",
      "Epoch 131: loss=0.04793\n",
      "Epoch 132: loss=0.09351\n",
      "Epoch 133: loss=0.04829\n",
      "Epoch 134: loss=0.07698\n",
      "Epoch 135: loss=0.07418\n",
      "Epoch 136: loss=0.08706\n",
      "Epoch 137: loss=0.08853\n",
      "Epoch 138: loss=0.14075\n",
      "Epoch 139: loss=0.10765\n",
      "Epoch 140: loss=0.07703\n",
      "Epoch 141: loss=0.04390\n",
      "Epoch 142: loss=0.04463\n",
      "Epoch 143: loss=0.08917\n",
      "Epoch 144: loss=0.07752\n",
      "Epoch 145: loss=0.05871\n",
      "Epoch 146: loss=0.08431\n",
      "Epoch 147: loss=0.04549\n",
      "Epoch 148: loss=0.03777\n",
      "Epoch 149: loss=0.03487\n",
      "Epoch 150: loss=0.04546\n",
      "Epoch 151: loss=0.07766\n",
      "Epoch 152: loss=0.02847\n",
      "Epoch 153: loss=0.04018\n",
      "Epoch 154: loss=0.04689\n",
      "Epoch 155: loss=0.03843\n",
      "Epoch 156: loss=0.05761\n",
      "Epoch 157: loss=0.08519\n",
      "Epoch 158: loss=0.07310\n",
      "Epoch 159: loss=0.07636\n",
      "Epoch 160: loss=0.06693\n",
      "Epoch 161: loss=0.06459\n",
      "Epoch 162: loss=0.07629\n",
      "Epoch 163: loss=0.09664\n",
      "Epoch 164: loss=0.05744\n",
      "Epoch 165: loss=0.03278\n",
      "Epoch 166: loss=0.05341\n",
      "Epoch 167: loss=0.04842\n",
      "Epoch 168: loss=0.10837\n",
      "Epoch 169: loss=0.04662\n",
      "Epoch 170: loss=0.03614\n",
      "Epoch 171: loss=0.06886\n",
      "Epoch 172: loss=0.05408\n",
      "Epoch 173: loss=0.07262\n",
      "Epoch 174: loss=0.05143\n",
      "Epoch 175: loss=0.06958\n",
      "Epoch 176: loss=0.06243\n",
      "Epoch 177: loss=0.13111\n",
      "Epoch 178: loss=0.05877\n",
      "Epoch 179: loss=0.05060\n",
      "Epoch 180: loss=0.03433\n",
      "Epoch 181: loss=0.03363\n",
      "Epoch 182: loss=0.03387\n",
      "Epoch 183: loss=0.04105\n",
      "Epoch 184: loss=0.01634\n",
      "Epoch 185: loss=0.07590\n",
      "Epoch 186: loss=0.02098\n",
      "Epoch 187: loss=0.02948\n",
      "Epoch 188: loss=0.05696\n",
      "Epoch 189: loss=0.08892\n",
      "Epoch 190: loss=0.03523\n",
      "Epoch 191: loss=0.04775\n",
      "Epoch 192: loss=0.03758\n",
      "Epoch 193: loss=0.04414\n",
      "Epoch 194: loss=0.05620\n",
      "Epoch 195: loss=0.06416\n",
      "Epoch 196: loss=0.04896\n",
      "Epoch 197: loss=0.03501\n",
      "Epoch 198: loss=0.06601\n",
      "Epoch 199: loss=0.03134\n",
      "Epoch 200: loss=0.01726\n"
     ]
    }
   ],
   "source": [
    "loss_hist = train(x_train, y_train, lr=2e-4, nb_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 495x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3.3,2),dpi=150)\n",
    "plt.plot(loss_hist)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.947\n",
      "Test accuracy: 0.953\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: %.3f\"%(compute_classification_accuracy(x_train,y_train, batch_size=256, shuffle=True)))\n",
    "print(\"Test accuracy: %.3f\"%(compute_classification_accuracy(x_test,y_test, batch_size=256, shuffle=True)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Oct 24 2022, 16:02:16) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "59c89e211e6a7d15bcf1fda4d2617053683adc75be6d99dab9047beccd836cf8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
