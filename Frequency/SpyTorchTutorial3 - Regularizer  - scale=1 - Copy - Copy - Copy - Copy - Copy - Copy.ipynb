{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For more details on surrogate gradient learning, please see: \n",
    "> Neftci, E.O., Mostafa, H., and Zenke, F. (2019). Surrogate Gradient Learning in Spiking Neural Networks.\n",
    "> https://arxiv.org/abs/1901.09948"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Training a spiking neural network on a simple vision dataset\n",
    "\n",
    "Friedemann Zenke (https://fzenke.net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Tutorial 2, we have seen how to train a simple multi-layer spiking neural network on the [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist). However, the spiking activity in the hidden layer was not particularly plausible in a biological sense. Here we modify the network from this previous tutorial by adding activity regularizer, which encourages solutions with sparse spiking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coarse network structure is dicated by the Fashion MNIST dataset. \n",
    "nb_inputs  = 28*28\n",
    "nb_hidden  = 100\n",
    "nb_outputs = 10\n",
    "\n",
    "time_step = 1e-2\n",
    "nb_steps  = 100\n",
    "\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "\n",
    "# Check whether a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")     \n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we load the Dataset\n",
    "root = os.path.expanduser(\"~/data/datasets/torch/mnist\")\n",
    "train_dataset = torchvision.datasets.MNIST(root, train=True, transform=None, target_transform=None, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root, train=False, transform=None, target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joshua\\AppData\\Local\\Temp\\ipykernel_14320\\1224777063.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x_train = np.array(train_dataset.data, dtype=np.float)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Temp\\ipykernel_14320\\1224777063.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x_test = np.array(test_dataset.data, dtype=np.float)\n"
     ]
    }
   ],
   "source": [
    "# Standardize data\n",
    "# x_train = torch.tensor(train_dataset.train_data, device=device, dtype=dtype)\n",
    "x_train = np.array(train_dataset.data, dtype=np.float)\n",
    "x_train = x_train.reshape(x_train.shape[0],-1)/255\n",
    "# x_test = torch.tensor(test_dataset.test_data, device=device, dtype=dtype)\n",
    "x_test = np.array(test_dataset.data, dtype=np.float)\n",
    "x_test = x_test.reshape(x_test.shape[0],-1)/255\n",
    "\n",
    "# y_train = torch.tensor(train_dataset.train_labels, device=device, dtype=dtype)\n",
    "# y_test  = torch.tensor(test_dataset.test_labels, device=device, dtype=dtype)\n",
    "y_train = np.array(train_dataset.targets, dtype=np.int64)\n",
    "y_test  = np.array(test_dataset.targets, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we plot one of the raw data points as an example\n",
    "data_id = 2\n",
    "plt.imshow(x_train[data_id].reshape(28,28), cmap=plt.cm.gray_r)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are working with spiking neural networks, we ideally want to use a temporal code to make use of spike timing. To that end, we will use a spike latency code to feed spikes to our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current2firing_time(x, tau=20, thr=0.3, tmax=1.0, epsilon=1e-7):\n",
    "    \"\"\" Computes first firing time latency for a current input x assuming the charge time of a current based LIF neuron.\n",
    "\n",
    "    Args:\n",
    "    x -- The \"current\" values\n",
    "\n",
    "    Keyword args:\n",
    "    tau -- The membrane time constant of the LIF neuron to be charged\n",
    "    thr -- The firing threshold value \n",
    "    tmax -- The maximum time returned \n",
    "    epsilon -- A generic (small) epsilon > 0\n",
    "\n",
    "    Returns:\n",
    "    Time to first spike for each \"current\" x\n",
    "    \"\"\"\n",
    "    idx = x<thr\n",
    "    x = np.clip(x,thr+epsilon,1e9)\n",
    "    T = tau*np.log(x/(x-thr))\n",
    "    T[idx] = tmax\n",
    "    return T\n",
    "\n",
    "def spike_fn(x):\n",
    "    out = torch.zeros_like(x)\n",
    "    out[x > 0] = 1.0\n",
    "    return out\n",
    "        \n",
    "def sparse_data_generator(X, y, batch_size, nb_steps, nb_units, shuffle=True ):\n",
    "    \"\"\" This generator takes datasets in analog format and generates spiking network input as sparse tensors. \n",
    "\n",
    "    Args:\n",
    "        X: The data ( sample x event x 2 ) the last dim holds (time,neuron) tuples\n",
    "        y: The labels\n",
    "    \"\"\"\n",
    "\n",
    "    labels_ = np.array(y,dtype=np.int64)\n",
    "    number_of_batches = len(X)//batch_size\n",
    "    sample_index = np.arange(len(X))\n",
    "\n",
    "    # compute discrete firing times\n",
    "    tau_eff = 20e-3/time_step\n",
    "    firing_times = np.array(current2firing_time(X, tau=tau_eff, tmax=nb_steps), dtype=np.int64)\n",
    "    unit_numbers = np.arange(nb_units)\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "\n",
    "    total_batch_count = 0\n",
    "    counter = 0\n",
    "    while counter<number_of_batches:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "\n",
    "        coo = [ [] for i in range(3) ]\n",
    "        for bc,idx in enumerate(batch_index):\n",
    "            \n",
    "            batch = [bc for _ in range(len(times))]\n",
    "            coo[0].extend(batch)\n",
    "            \n",
    "\n",
    "        i = torch.LongTensor(coo).to(device)\n",
    "        v = torch.FloatTensor(np.ones(len(coo[0]))).to(device)\n",
    "    \n",
    "        X_batch = torch.sparse.FloatTensor(i, v, torch.Size([batch_size,nb_steps,nb_units])).to(device)\n",
    "        y_batch = torch.tensor(labels_[batch_index],device=device)\n",
    "\n",
    "        yield X_batch.to(device=device), y_batch.to(device=device)\n",
    "\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_image(image, scale, time_step):\n",
    "    scaled_image = image*scale\n",
    "    for i,prob in enumerate(scaled_image):\n",
    "        if (prob > 1):\n",
    "            new_prob = 1\n",
    "            scaled_image[i] = new_prob\n",
    "    rate_of_scaled_image = scaled_image/time_step\n",
    "    average_rate = torch.mean(rate_of_scaled_image)\n",
    "    return scaled_image, average_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images2spike(x, y, batch_size, shuffle, **kwargs):  \n",
    "    '''Converts images to spike trains'''\n",
    "    labels_ = np.array(y,dtype=np.int64)\n",
    "    number_of_batches = len(x)//batch_size\n",
    "    sample_index = np.arange(len(x))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "\n",
    "    total_batch_count = 0\n",
    "    counter = 0\n",
    "\n",
    "    batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "    while counter < number_of_batches:\n",
    "        x_batch = torch.empty((len(x[batch_index]), nb_steps, nb_inputs)).to(device)\n",
    "        for i, image in enumerate(x[batch_index]):\n",
    "            tensor_image = torch.Tensor(image) # probabilities tensor\n",
    "            zero_image = torch.zeros(tensor_image.shape)\n",
    "            spike_train = torch.empty((nb_steps, nb_inputs))\n",
    "            for t in range(nb_steps):\n",
    "                spike_t = torch.bernoulli(tensor_image)\n",
    "                spike_train[t] = spike_t\n",
    "            x_batch[i] = spike_train\n",
    "        y_batch = torch.tensor(labels_[batch_index],device=device) \n",
    "\n",
    "        yield x_batch,  y_batch\n",
    "\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup of the spiking network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "\n",
    "alpha   = float(np.exp(-time_step/tau_syn))\n",
    "beta    = float(np.exp(-time_step/tau_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init done\n"
     ]
    }
   ],
   "source": [
    "weight_scale = 0.0015\n",
    "\n",
    "w1 = torch.empty((nb_inputs, nb_hidden),  device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w1, mean=0.0, std=weight_scale)\n",
    "\n",
    "w2 = torch.empty((nb_hidden, nb_outputs), device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w2, mean=0.0, std=weight_scale)\n",
    "\n",
    "print(\"init done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_voltage_traces(mem, spk=None, dim=(3,5), spike_height=5):\n",
    "    gs=GridSpec(*dim)\n",
    "    if spk is not None:\n",
    "        dat = 1.0*mem\n",
    "        dat[spk>0.0] = spike_height\n",
    "        dat = dat.detach().cpu().numpy()\n",
    "    else:\n",
    "        dat = mem.detach().cpu().numpy()\n",
    "    for i in range(np.prod(dim)):\n",
    "        if i==0: a0=ax=plt.subplot(gs[i])\n",
    "        else: ax=plt.subplot(gs[i],sharey=a0)\n",
    "        ax.plot(dat[i])\n",
    "        ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurrGradSpike(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Here we implement our spiking nonlinearity which also implements \n",
    "    the surrogate gradient. By subclassing torch.autograd.Function, \n",
    "    we will be able to use all of PyTorch's autograd functionality.\n",
    "    Here we use the normalized negative part of a fast sigmoid \n",
    "    as this was done in Zenke & Ganguli (2018).\n",
    "    \"\"\"\n",
    "    \n",
    "    scale = 100.0 # controls steepness of surrogate gradient\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we compute a step function of the input Tensor\n",
    "        and return it. ctx is a context object that we use to stash information which \n",
    "        we need to later backpropagate our error signals. To achieve this we use the \n",
    "        ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        out = torch.zeros_like(input)\n",
    "        out[input > 0] = 1.0\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor we need to compute the \n",
    "        surrogate gradient of the loss with respect to the input. \n",
    "        Here we use the normalized negative part of a fast sigmoid \n",
    "        as this was done in Zenke & Ganguli (2018).\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad = grad_input/(SurrGradSpike.scale*torch.abs(input)+1.0)**2\n",
    "        return grad\n",
    "    \n",
    "# here we overwrite our naive spike function by the \"SurrGradSpike\" nonlinearity which implements a surrogate gradient\n",
    "spike_fn  = SurrGradSpike.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_snn(inputs):\n",
    "    h1 = torch.einsum(\"abc,cd->abd\", (inputs, w1))\n",
    "    syn = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "    mem = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "\n",
    "    mem_rec = []\n",
    "    spk_rec = []\n",
    "\n",
    "    # Compute hidden layer activity\n",
    "    for t in range(nb_steps):\n",
    "        mthr = mem-1.0\n",
    "        out = spike_fn(mthr)\n",
    "        rst = out.detach() # We do not want to backprop through the reset\n",
    "\n",
    "        new_syn = alpha*syn +h1[:,t]\n",
    "        new_mem = (beta*mem +syn)*(1.0-rst)\n",
    "\n",
    "        mem_rec.append(mem)\n",
    "        spk_rec.append(out)\n",
    "        \n",
    "        mem = new_mem\n",
    "        syn = new_syn\n",
    "\n",
    "    mem_rec = torch.stack(mem_rec,dim=1)\n",
    "    spk_rec = torch.stack(spk_rec,dim=1)\n",
    "\n",
    "    # Readout layer\n",
    "    h2= torch.einsum(\"abc,cd->abd\", (spk_rec, w2))\n",
    "    flt = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out_rec = [out]\n",
    "    spk_rec2 = []\n",
    "    for t in range(nb_steps):\n",
    "        mthr = out-1.0\n",
    "        output = spike_fn(mthr)\n",
    "        rst = output.detach() # We do not want to backprop through the reset\n",
    "\n",
    "        new_flt = alpha*flt +h2[:,t]\n",
    "        new_out = (beta*out +flt)*(1.0-rst)\n",
    "\n",
    "        flt = new_flt\n",
    "        out = new_out\n",
    "\n",
    "        out_rec.append(out) # membrane potential\n",
    "        spk_rec2.append(output) # spike train\n",
    "\n",
    "    out_rec = torch.stack(out_rec,dim=1)\n",
    "    spk_rec2 = torch.stack(spk_rec2, dim=1)\n",
    "\n",
    "    return spk_rec2,  spk_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_data, y_data, scale=1, lr=1e-3, nb_epochs=10):\n",
    "    params = [w1,w2]\n",
    "    optimizer = torch.optim.Adamax(params, lr=lr, betas=(0.9,0.999))\n",
    "\n",
    "    log_softmax_fn = nn.LogSoftmax(dim=1)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    \n",
    "    loss_hist = []\n",
    "    for e in range(nb_epochs):\n",
    "        local_loss = []\n",
    "        for x_local, y_local in images2spike(x_data, y_data, batch_size, shuffle=True):\n",
    "            output, spks = run_snn(x_local)\n",
    "            spike_count =torch.sum(output,1)\n",
    "            mean_firing_rate = spike_count/(nb_steps*time_step)\n",
    "\n",
    "            log_p_y = log_softmax_fn(mean_firing_rate)\n",
    "            \n",
    "            # Here we set up our regularizer loss\n",
    "            # The strength paramters here are merely a guess and there should be ample room for improvement by\n",
    "            # tuning these paramters.\n",
    "            reg_loss = 1e-6*torch.sum(spks) # L1 loss on total number of spikes\n",
    "            reg_loss += 1e-7*torch.mean(torch.sum(torch.sum(spks,dim=0),dim=0)**2) # L2 loss on spikes per neuron\n",
    "\n",
    "            # Here we combine supervised loss and the regularizer\n",
    "            loss_val = loss_fn(log_p_y, y_local) \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "            local_loss.append(loss_val.item())\n",
    "        mean_loss = np.mean(local_loss)\n",
    "        print(\"Epoch %i: loss=%.5f\"%(e+1,mean_loss))\n",
    "        loss_hist.append(mean_loss)\n",
    "        \n",
    "    return loss_hist\n",
    "        \n",
    "        \n",
    "def compute_classification_accuracy(x_data, y_data, batch_size, shuffle, **kwargs):\n",
    "    \"\"\" Computes classification accuracy on supplied data in batches. \"\"\"\n",
    "    accs = []\n",
    "    for x_local, y_local in images2spike(x_data, y_data, batch_size, shuffle=True, **kwargs):\n",
    "        output, _ = run_snn(x_local)\n",
    "        spike_count =torch.sum(output,1)\n",
    "        mean_firing_rate = spike_count/(nb_steps*time_step)\n",
    "        _, am = torch.max(mean_firing_rate, 1)\n",
    "        tmp = np.mean((y_local==am).detach().cpu().numpy()) # compare to labels\n",
    "        accs.append(tmp)\n",
    "    return np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=2.30258\n",
      "Epoch 2: loss=2.25675\n",
      "Epoch 3: loss=1.60788\n",
      "Epoch 4: loss=1.06620\n",
      "Epoch 5: loss=0.73751\n",
      "Epoch 6: loss=0.46613\n",
      "Epoch 7: loss=0.34781\n",
      "Epoch 8: loss=0.34779\n",
      "Epoch 9: loss=0.37553\n",
      "Epoch 10: loss=0.44368\n",
      "Epoch 11: loss=0.32741\n",
      "Epoch 12: loss=0.32081\n",
      "Epoch 13: loss=0.21497\n",
      "Epoch 14: loss=0.16980\n",
      "Epoch 15: loss=0.15901\n",
      "Epoch 16: loss=0.18081\n",
      "Epoch 17: loss=0.24275\n",
      "Epoch 18: loss=0.20838\n",
      "Epoch 19: loss=0.16174\n",
      "Epoch 20: loss=0.15907\n",
      "Epoch 21: loss=0.17821\n",
      "Epoch 22: loss=0.20005\n",
      "Epoch 23: loss=0.18301\n",
      "Epoch 24: loss=0.14898\n",
      "Epoch 25: loss=0.15268\n",
      "Epoch 26: loss=0.17312\n",
      "Epoch 27: loss=0.09022\n",
      "Epoch 28: loss=0.11395\n",
      "Epoch 29: loss=0.08201\n",
      "Epoch 30: loss=0.15161\n",
      "Epoch 31: loss=0.22830\n",
      "Epoch 32: loss=0.11330\n",
      "Epoch 33: loss=0.13021\n",
      "Epoch 34: loss=0.11712\n",
      "Epoch 35: loss=0.11874\n",
      "Epoch 36: loss=0.09806\n",
      "Epoch 37: loss=0.12773\n",
      "Epoch 38: loss=0.09665\n",
      "Epoch 39: loss=0.09623\n",
      "Epoch 40: loss=0.09944\n",
      "Epoch 41: loss=0.06480\n",
      "Epoch 42: loss=0.10317\n",
      "Epoch 43: loss=0.03835\n",
      "Epoch 44: loss=0.09047\n",
      "Epoch 45: loss=0.15485\n",
      "Epoch 46: loss=0.11131\n",
      "Epoch 47: loss=0.08274\n",
      "Epoch 48: loss=0.07204\n",
      "Epoch 49: loss=0.07042\n",
      "Epoch 50: loss=0.10857\n",
      "Epoch 51: loss=0.11035\n",
      "Epoch 52: loss=0.17435\n",
      "Epoch 53: loss=0.14221\n",
      "Epoch 54: loss=0.04418\n",
      "Epoch 55: loss=0.08955\n",
      "Epoch 56: loss=0.12923\n",
      "Epoch 57: loss=0.07738\n",
      "Epoch 58: loss=0.12759\n",
      "Epoch 59: loss=0.06055\n",
      "Epoch 60: loss=0.11362\n",
      "Epoch 61: loss=0.07585\n",
      "Epoch 62: loss=0.11065\n",
      "Epoch 63: loss=0.06051\n",
      "Epoch 64: loss=0.06554\n",
      "Epoch 65: loss=0.03299\n",
      "Epoch 66: loss=0.04309\n",
      "Epoch 67: loss=0.03132\n",
      "Epoch 68: loss=0.10407\n",
      "Epoch 69: loss=0.04456\n",
      "Epoch 70: loss=0.11073\n",
      "Epoch 71: loss=0.13774\n",
      "Epoch 72: loss=0.10488\n",
      "Epoch 73: loss=0.11932\n",
      "Epoch 74: loss=0.05892\n",
      "Epoch 75: loss=0.01944\n",
      "Epoch 76: loss=0.06917\n",
      "Epoch 77: loss=0.07407\n",
      "Epoch 78: loss=0.06461\n",
      "Epoch 79: loss=0.07799\n",
      "Epoch 80: loss=0.04118\n",
      "Epoch 81: loss=0.04643\n",
      "Epoch 82: loss=0.02849\n",
      "Epoch 83: loss=0.04831\n",
      "Epoch 84: loss=0.07291\n",
      "Epoch 85: loss=0.06999\n",
      "Epoch 86: loss=0.08809\n",
      "Epoch 87: loss=0.02432\n",
      "Epoch 88: loss=0.03450\n",
      "Epoch 89: loss=0.07265\n",
      "Epoch 90: loss=0.04757\n",
      "Epoch 91: loss=0.04897\n",
      "Epoch 92: loss=0.03728\n",
      "Epoch 93: loss=0.06430\n",
      "Epoch 94: loss=0.05079\n",
      "Epoch 95: loss=0.05525\n",
      "Epoch 96: loss=0.03987\n",
      "Epoch 97: loss=0.06652\n",
      "Epoch 98: loss=0.07621\n",
      "Epoch 99: loss=0.04901\n",
      "Epoch 100: loss=0.04312\n"
     ]
    }
   ],
   "source": [
    "loss_hist = train(x_train, y_train, lr=2e-4, nb_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdsAAAFDCAYAAAByT6QaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAABcSAAAXEgFnn9JSAAA9FUlEQVR4nO3dd3hUVcIG8PfOJJPeCQkhhEDoJaEEkBJ6CUURECyLgvqhK7ogoKuuhV1w14awlsWCBRQBQQEFVBSREA1FCL0FQgkhlPQ+mZnM+f4IuZlhJiSEmUx7f8/D82RumXvmAHnnnHvuOZIQQoCIiIisRmHrAhARETk7hi0REZGVMWyJiIisjGFLRERkZQxbIiIiK2PYEhERWRnDloiIyMoYtkRERFbGsCUiIrIyhi0REZGVMWyJiIisjGFLRERkZQzbWtx111246667bF0MIiJyAm62LoC9Sk9Pt3URiIjISbBlS0REZGUMWyIiIitj2BIREVkZw5aIiMjKGLZERERWxrAlIiKyMoYtERGRlTFsrWzL4csoLNfauhhERGRDDFsrqdQLvPbjCTy5KhVPrUqFrlJv6yIREZGNMGytZNOhLHyUdBYAkHw6B69uOWHjEhERka0wbK3krrgIjO3aTH69POU8Vu6+YMMSERGRrTBsrUShkLBochy6Ng+Qt83//hhSzuTYsFRERGQLDFsr8lIpseyheIT5ewCouo/715X7cT6n1MYlIyKixsSwtbLwAE8seygenu5VVV2k1mFZ8lkbl4qIiBoTw7YRxEYGYvawdvLr87ls2RIRuRKGbSOJDPKSfy5W62xYEiIiamwM20bi5+km/8ywJSJyLQzbRuLn6S7/XKzmjFJERK6EYdtI/A1atkVs2RIRuRSGbSMxbNlqdHqotZU2LA0RETUmhm0jMbxnC/C+LRGRK2HYNhJvlRJKhSS/5n1bIiLXwbBtJJIkwdeDI5KJiFwRw7YR8fEfIiLXxLBtRP58/IeIyCUxbBsRW7ZERK6JYduIDB//KWLLlojIZTBsG5E/W7ZERC6JYduI2I1MROSaGLaNiPMjExG5JocM27KyMmzcuBGPPvooYmNj4e/vDx8fH8TFxWHBggUoKSmxdRHN8jOaH5lhS0TkKhwybFetWoUJEybgs88+g16vR2JiIhISEnDu3DnMnz8fvXr1wrVr12xdTBPGLVt2IxMRuQqHDFuVSoUnnngCaWlpOHr0KNauXYuffvoJp06dQvfu3XHy5Ek8/fTTti6mCd6zJSJyTZIQQti6EJa0a9cu9OvXDx4eHigqKoJKpWrQ+3Tu3BkAcOzYMYuVLSktG9M+2wsAiA7xxo5nh1jsvYmIyH45ZMv2ZuLi4gAAFRUVyM3NtXFpjLFlS0TkmpwubM+ePQsAcHd3R3BwsI1LY4zP2RIRuSa3ug9xLO+88w4AIDExER4eHnUeX91dfKP09HTExMRYtGxGC8hXVi0g7+mutOg1iIjI/jhVy/aHH37Ap59+Cnd3dyxcuNDWxTHBBeSJiFyT07RsT5w4galTp0IIgbfeeku+d1uX2gZA1dbivR1e7lULyFfqq8akFau1CPWru/VNRESOzSlatpmZmUhMTER+fj7mzp2L2bNn27pIZkmSxEFSREQuyOHDNicnByNGjEBGRgYefvhhLFq0yNZFuinOIkVE5HocOmyLi4sxevRonDx5EhMnTsSyZcsgSZKti3VTfh6cRYqIyNU4bNhWVFRg/Pjx2LdvH0aNGoXVq1dDqbT/kb3G3chs2RIRuQKHDNvKykrcf//9+O2335CQkID169c3eKaoxubvxZYtEZGrccjRyO+//z42bNgAAGjSpAlmzpxp9rhFixahSZMmjVm0Ohnfs2XYEhG5AocM2/z8fPnn6tA155///Kfdha0/17QlInI5DtmN/M9//hNCiDr/REdH27qoJvjoDxGR63HIsHVkHCBFROR6GLaNjAvIExG5HoZtI2M3MhGR62HYNjI/DpAiInI5DNtGxkd/iIhcD8O2kd346I8QwoalISKixsCwbWT+Bi1bbaVAhU5vw9IQEVFjYNg2MsN7tgBX/iEicgUM20bm6a6Am6JmZSKOSCYicn4M20bGBeSJiFwPw9YG+PgPEZFrYdjaAFu2RESuhWFrA5wfmYjItTBsbYDzIxMRuRaGrQ0YTmxRVM6WLRGRs2PY2gCnbCQici0MWxvw5wApIiKXwrC1AT76Q0TkWhi2NsBHf4iIXAvD1gaMWrYVbNkSETk7hq0NsGVLRORaGLY2wLAlInItDFsbuHGAFBeQJyJybgxbG+AC8kREroVhawP+XjcsIM9ZpIiInBrD1gY83BRwV9YsIM9ZpIiInBvD1gaqFpA3mB+ZE1sQETk1hq2NBBp0JReyG5mIyKkxbG0kwNsgbMsYtkREzoxhayOGLduCMo0NS0JERNbGsLWRQG+V/HMBu5GJiJwaw9ZGAr0NW7YMWyIiZ8awtZFAr5qWLQdIERE5N4atjRi3bHnPlojImTFsbcQwbPPZjUxE5NQYtjYSwOdsiYhcBsPWRoxGI7MbmYjIqTFsbeTGGaT0ei6zR0TkrBi2NmJ4z1YvgOIKLkZAROSsGLY24ufpDqlm4R9O2UhE5MQYtjaiVEjwN1j5p6Cc922JiJwVw9aGgjiLFBGRS2DY2lAA50cmInIJDFsbMhqRzMd/iIicFsPWhjiLFBGRa2DY2pDxmrYMWyIiZ8WwtSHje7bsRiYiclYMWxsyvmfLli0RkbNi2NqQ0TJ7HI1MROS03BrrQjqdDp9++imOHDmCli1b4rHHHkNAQEBjXd4ucU1bIiLXYPGW7YIFC6BUKpGUlCRvE0Jg2LBhmDlzJpYuXYrnn38evXr1QlFRkaUv71AMV/7hMntERM7L4mH7yy+/oHnz5hg0aJC8bf369UhOTkbXrl3x0UcfYcKECThz5gz+97//WfryDuXG0chCcOUfIiJnZPGwPXv2LDp27Gi07ZtvvoEkSVizZg1mzJiBdevWISoqCuvWrbP05R2KYctWpxco1VTasDRERGQtFg/b3NxchIaGGm1LTk5Gu3bt0KFDBwCAJEmIj4/HhQsXLH15h+LvaXzLnPdtiYick8XDNjQ0FNnZ2fLrs2fPIisry6hbGQBUKhU0GtcOFzelAn4GgcuJLYiInJPFw7ZTp05ITk7GxYsXAQDLli2DJEkYM2aM0XHnz59Hs2bNLH15hxPIlX+IiJyexcN27ty5UKvViI2NRY8ePfDGG2+gVatWSExMlI8pLCxEamoq4uLiLH15hxPoxVmkiIicncXDdtSoUVi6dCkCAgJw6tQpDBgwABs2bIBKVRMqX3zxBTQaDYYNG2bpyzsctmyJiJyfJGzwvEl5eTk0Gg18fX2hVCob+/L10rlzZwDAsWPHrHqdp1alYvPhywCAZ0e1x5ND2lj1ekRE1PgabQYpQ15eXvDy8rLFpe1OkOFiBByNTETklCzejVxWVoaMjAyUlpYabS8sLMQLL7yAcePG4cknn8S5c+csfWmHxG5kIiLnZ/GW7auvvoo33ngDe/bsQXx8PABAo9Ggb9++OHXqlDxL0rfffotDhw4hLCzM0kVwKAFeXIyAiMjZWbxl++uvv6JVq1Zy0ALAqlWrcPLkSQwZMgRbt27F008/jWvXrmHJkiWWvrzDMZofmS1bIiKnZPGwzcjIQLt27Yy2bdy4EQqFAsuXL8eIESOwePFitG/fHlu2bLH05R2O0fzIfPSHiMgpWTxs8/PzERQUZLQtJSUFXbt2RWRkpLwtNjZWnvjClRnes81ny5aIyClZPGzDw8ORlZUlvz527BhycnJMpmuUJMnSl3ZIhmFbyJV/iIicksXDtnv37vjjjz9w8OBBAMCSJUsgSRLGjRtndNzp06cRERFh6cs7nACDGaQ0lXqUa7nyDxGRs7F42D7//PPQ6/WIj49HSEgIPvvsM8TFxWHo0KHyMdeuXcOhQ4fQs2dPS1/e4RiORgb4+A8RkTOyeNj26dMH3333HQYMGIDw8HBMnToV33//PRSKmkutWrUKfn5+RvMluyqVmwK+Hlz5h4jImdlkukZH0FjTNQJA/9e341JBOQBg1Yw+6BfTxOrXJCKixmPxli3duhsHSRERkXOx2tzIWq0WGzZsQHJyMrKysiBJEpo1a4aEhARMmDAB7u7udb+JizCaspGzSBEROR2rhO0ff/yBBx54AJmZmSaPsixduhQtWrTAqlWr0K9fP2tc3uEYrWnLli0RkdOxeNimpaVh9OjRKCkpQc+ePTF16lRER0cDAC5cuICVK1di3759GD16NPbt24e2bdtauggOJ8Cbs0gRETkzi4ftv//9b5SUlGDJkiWYPXu2yf5Zs2bh3XffxdNPP41///vfWL58uaWL4HCMpmwsZcuWiMjZWGUhgu7du5sN2mqzZs1C9+7dsW3btgZfZ//+/Xj99dcxceJENG/eHJIkwdPTs8HvZ0uBbNkSETk1i7dss7OzTaZmNKdDhw639VjNwoUL8d133zX4fHtiuIB8TgnDlojI2Vg8bENCQpCWllbncWlpaQgODm7wdfr27Yu4uDj06tULvXr1Qnh4eIPfy9YiAr3kny9ff96WiIich8XDdsiQIVizZg2WLVuGGTNmmD1m2bJl2L9/Px544IEGX+e5555r8Ln2xjBsrxZXQFeph5uSj0ATETkLi88gdeLECcTHx0OtVmPgwIF44IEHEB0dDUmScO7cOXz11VdITk6Gl5cX/vzzT3Ts2NEi15UkCR4eHlCr1RZ5v8acQUqtrUSHl3+SX6c8P9QogImIyLFZvGXbsWNHfP/99/jLX/6CpKQk7Ny502i/EAJhYWH46quvLBa0js7TXYkQHxVyS6vu12YVlDNsiYiciFUmtRg2bBjOnj2LtWvXyjNIAUBERAQSEhIwZcoUeHt7W+PSt6y6BXuj9PR0xMTENFo5IgK95LC9VFCO+Ea7MhERWZvVpmv09vbG9OnTMX36dLP7161bh8uXL2PWrFnWKoJDiQj0xJFLhQCArALLdIUTEZF9sFrY1mXx4sXYu3evzcO2tnuytbV4rcWw2ziLI5KJiJwKh7zaiYgAhi0RkbNi2NoJo5ZtIbuRiYicCcPWTkQE1kw1yZYtEZFzYdjaieYGLdvCci1KKnQ2LA0REVkSw9ZONPH1gLtSkl9z2kYiIufhsGG7ZcsW3HHHHfIfANBoNEbbtmzZYuNS1p9CIaGZwSCpSwxbIiKncduP/iiVSkuU45ZlZ2djz549RtuEEEbbsrOzG7tYt6VZgCcy8soA8FlbIiJncttheztTK0uSVPdBtbjZhBmOqjmftSUickq3HbZ6vd4S5SDc+PgPw5aIyFk47D1bZ8RZpIiInBPD1o4YP2vLe7ZERM6CYWtHDFu2lwvLoddbdKlhIiKyEYatHWkWUNOy1VYK5JRU2LA0RERkKQxbO+Ln6Q5/z5oxa3zWlojIOTBs7YzxICnetyUicgYMWzvT/Ib7tkRE5PgYtnbGsGXLbmQiIufAsLUzzbjUHhGR02HY2pnmvGdLROR0GLZ2hrNIERE5H4atnTEM29xSDdTaShuWhoiILIFha2fC/DygMFgMia1bIiLHx7C1M25KBcL9awZJcUQyEZHjY9jaoRbB3vLP53PLbFgSIiKyBIatHYoO8ZF/vpBTasOSEBGRJTBs7VDLJmzZEhE5E4atHWpl2LLNZcuWiMjRMWztUEvDsM0r47q2REQOjmFrh1qG1HQja3R6XCniTFJERI6MYWuHfDzcEOrnIb8+z65kIiKHxrC1U9EGrdsLHCRFROTQGLZ2yvC+7Xk+/kNE5NAYtnbKsGXLbmQiIsfGsLVT0U0MH/9hNzIRkSNj2Nopw1mkzueWQgg+/kNE5KgYtnYqyqAbWa3V41pxhQ1LQ0REt4Nha6f8Pd0R4qOSX3OQFBGR42LY2rGWfPyHiMgpMGzt2I33bYmIyDExbO2Y0RzJbNkSETkshq0dizZYau8c79kSETkshq0di75hqT0+/kNE5JgYtnbMMGxLNZXIKdHYsDRERNRQDFs7FuDtjkBvd/k1F5InInJMDFs7Z7QgAQdJERE5JIatnTNeao8tWyIiR8SwtXPRbNkSETk8hq2da2Ww+s+hiwUckUxE5IAYtnauT+tg+eeMvDKcuFxcr/MqdJV4es0B9H99O7Yeu2Kt4hERUT0wbO1cswAvdGsRKL/+6ejlep23IuU8Nh7MwqWCcryw/gh0lXorlZCIiOrCsHUAo7uEyz//eLTuVmpeqQbvbT9j9HrPuTyrlI2IiOrGsHUAo7s0k38+fa0EZ66V3PT4d7aloVitM9r2w5H6tYiJiMjyGLYOICrEG52a+cuvb9aVfOZaCVbuyTDZvvXYFVTqObiKiMgWGLYOor5dya/9cEIO1eaBXnBXSgCAnBIN9rIrmYjIJhi2DmJ015qwPZZVhAwzz9zuOHUNv568Jr9+aWxH9G/TRH7NrmQiIttg2DqINk390Kapr/z6p2M1wanXC3ySfBYzvtgnb+sVHYTELuEYY3C/9yd2JRMR2QTD1oEkdq5p3W4+fBnHs4pwOLMA05f/iVe3nIC2sipI3ZUSXh7XCZIkYUSnMCgVVV3J2cUV2H8h3yZlJyJyZQxbB5JocN/2cGYhxrybjLve/wM707Ll7WH+HljxSG/ERgYCAIJ8VOgXEyLvZ1cyEVHjY9g6kM4R/mhpsDDBjYZ3DMOPsweiX0wTo+1jutZ0Jf949DJKKnQ3nkpERFYkCU62a1bnzp0BAMeOHbNxSYztTMvGK98dRa7BQvIhvio8mtAaU/tEQZIkk3NySyrQ+z+/Gt2vjQzyQucIf8wa1hadIwIapexERK6KYVsLew3bhnrw0z1IPp1jsj0q2Bs7nhkMhcI0pImIyDLYjewi5t/ZCf1iQuCtUhptz8grw97zfP6WiMia3GxdAGocbZr6YdWMO6DXC1wqKMcz6w7J8yVvSL2EO1qH1PEORETUUGzZuhiFQkKLYG/c3ztK3vbDkctQayttWCoiIufGsHVRIzuHyV3KxRU6/HriWh1nEBFRQzFsXZS3ys1okowNBy7ZsDRERM6NYevCJvRoLv+849Q15JVqbnK0Kb1e4Jv9mfju4CVOA0lEdBMMWxfWL6YJmvp5AAB0eoHNh7Nu6fxFP5/CM+sOYfaag3jyq1SHve+r0elxtUht62IQkRNj2LowpULC+G4R8utb6Uo+eaUIH+88K7/+6dgVPPTZXhSWay1aRmsrKNNg5JIk9PnPr3h/+2lbF4eInBTD1sXd3b2mK/lARgHSs0vqPEevF3hxw1Hobug63nsuD1M+3IXLheUWL6e1fLTzLM5fX67ww6SzDts6JyL7xrB1cZ2a+aN9mJ/8etbqAyjT3Hzu5LX7LhqtHtTX4BndU1eLce9Hu5F/C/d/D2Tk4/UfT+KHI5ehq9TfQulvT16pBitSzsuvSyp0Ros6EBFZCsPWxUmShL8Obi2/PpZVhKfXHIS+lgFPOSUVeO3Hk/LrsV2bYdWMPnhqSBt5W0ZeGWZ+lQptHcGZVVCO2WsOYMLSFHyYlI6ZX6Vi0Fs78EnyWRSrrd8dvSz5LMo0xi1ZropERNbAsCVM6B6J6f2i5dc/H7+KN7aeNDmupEKHf6w/It+X9fVwk9fNfWZUe8wb0U4+dtfZXLy6+bjZ6xWptVj88ykMfXsHvjtoPCjrUkE5Xt1yAv1e346fjtYdfKUVOjRkeu8bW7XVtp24xq7kWpRU6HAht9TWxSBySAxbAgC8PK4ThrQPlV9/lHQWL6w/gh2nrqFMo8PaPy9i8Fs78PPxq/Ix80a2Q3iAp/z6qaFtcFdczYCrFbsu4Ks9F+QwLFJr8e6vpzHg9e14d/sZqLU1Ld+oYG+4GSyGUKzW4YmvUs0GIlA1QOvR5X+i8/ytmPRByi0H5CcGrdogb3d5gg92JZt3pVCNEYuTMOitHXhqVSrKNfxCQnQruOpPLZxt1Z/6KKnQ4Z4PUnDySrHRdkkCbvxX0is6CGse6wvlDasFqbWVmPzhLhy5VChvU7kpEOjljjJNpclauk18PfDsqHa4p2cLXC1SY8Wu8/hqd4bRcY8Pao1nR7ZHQbkWWQXlWP7HeWw4eMmoTAvHd8aDfaPr9TnzSjVIeGM7Sq8Hxt8T2+N4VhE2H65qSd/dLQL/va97vd7LXhSptdh+4hp6twpGRKCXxd//yVWp2HK4pqchNjIAyx6KR5i/503OIqJqDNtauGLYAlXduPd8kILLheafO/VwU+DxQTH466DW8FaZX8fiSqEad77/O7KLK2q9jp+HGx7uH40ZA1vDz9PdaN/pq8WY9tleZBmUQSEBN5s3o0WwF36bNxhuyro7a9746SQ+2JEOAAj0dsfvzw1Fclo2nvgqFUBV9/i+l4bD0115s7exG9pKPSYuTcGRS4Xw9XDD14/fYdE1iv84k4O/fLLHZHu4vyc+mRaPLs25HjJRXdiNTEaaB3ph65yB+PeELhjRKQw+Bkvyje8Wge3PDMbcEe1qDVoACA/wxCcPxaOJr4fJPj8PN8wa1ha/PzcUc0e2NwlaAGgb5of1M/ujQ3jNKGlzQRsT6iO3rC/mlePHo1fq/HxXCtX4/I9z8usZCa3h6+GGwe2bmu1K1lXqUVimbdB94cbyxa4Lck9CSYUOD3/+Jy4VWObxK41Oj/nf13zhDPSu+fu6UqTGfR/vxsW8spu+hxCiUUeZW9u1IjWeWXcI9328C7vSc21dHHIQbNnWwlVbtjfS6PQ4cqkAAV7uaNPUr+4TDFTqBXJLK1BYpkVBuRYanR5dIwPgbyZgzSlSa/HkV6lGi957uivQqokvHu4fjUk9IjFv7UFsvD7Iqktzf2x6agAkSartLfHsukNYtz8TANDEV4Udzw6Br0fVF4enVqXKXcnDOzZFp2b+WLknA3mlGkSHeGNsbDOMi41Ah3A/qLV6lGl0cFMqEOBl/HnKNDq89sNJJJ/Oxj09IzFzcBsoFLWX6XZcK1Zj2KIkFN/QPd8uzBfr/trPpGy36uOd6fjPD1WD5SQJ+O7J/jh0sQD/3HRcnqLzsYGt8Y8xHc2eX1imxV9X7sfuc7mYM7wdZg1rK+/T6wXe2HoS245fxczBbTCpZ+RtlbUxbD12Bc9/exj5ZVWDBN0UEv4zoSum9GohH6PWVqJCq0eA9+3VPTkXhm0tGLb2Qa8XOHmlGB7uCjT184Cvh5tRmB7PKsKYd5Pl1ysf7YMBbZvgcGYB1u3LRNfmAZgcHwlJknDyShFGv5Ms3+t99e4umHpHS/ncH49clruSb0VC2yZ4LrEDujQPQHp2CZ5YuR9pV2smBxnesSmW3NvNbCv+ds1bewjfplZ9efBwU6BCV9OCvKN1MFY80hsebvXvDtdV6nHySjFKK3QoKNdi7tcH5XvbD/SJwn8mdAVQNcDs1S0nAAAhPirsemEYVG7GHWXFai2mfroXhy4WyNs+erAnRl1fAOODHel446eqIHdTSPh5zkC0DvWVj01Jz8HWo1cwqWckYiMDjd67SK3FnrN56N0q+La/UNRHmUaHBZuOY82fF83uf3JIDAa2DcW6/Zn44chllGsr8fLYTnhkQCurl40cA8O2FgxbxzHts71Iut7t26dVMDqE++GL3RfkUL0zLgJv3ROLx7/cLx8XE+qDrU8PNLrHW66pRM9XfzF59ra+RnYKQ0p6rskgsOrrvf9AD0QEeEGhqOoWLyjTIKdEg/xSDcIDPE3ufZZpdPgw6Sy0lXrMGtoWXirj0Nx/IQ+TPtglv144vjOuFlXg/d/OyNt6RAXivQd6oHk9Bk0dvVSIx7/cb7YLOsjbHdvnDUaQjwpAVYu113+2QXM93D/4Sw+M7trMqOzTPtuLP8/nG71PgJc7fpidgMy8MjzwyR6jBSyGdwzDJ9PiAQCHMwsw6YMUaCsFVG4KfPxgTwxu3xRA1Uj0aZ/txdWiCrRu4oMNT/a3SOAevFiAj3emY3D7ppgSX9NSFULg4eV/YsepmlHqXu5KeKuUyL3J5C1uCgmbZw1Ah3D/2y4bOT6GbS0Yto4jJT0HDywzHcBjqFUTH5zLqXlGdNlD8RjRKczkuBfWH8bqvVWtl3B/TzzUryWGdwzDzrRsbDqUhUOZhSbn1KZDuJ/JyO6beXJIDJ4Z2R6SJKFMo8P0z//E3nN5AIBJPSLx9pQ4+dhKvcCd7/2O45eLAFTNBLbpbwOgkIB56w5hfWrNPNcBXu5YNDnO7OetdvRSIf7yyZ5a57Z+bWJX3N87ymjb02sOyF34g9qFYsUjvQFUdaM+uuJP/HGm5n6m4Yj2uBaBuFxQjmtmBtCtfLQPukUFYty7yfI0mgCgUirw0YM94ePhhkdX/Ilidc0XmhGdwvDxgz1vevugLkVqLQa++RsKrncPfzY9HkM7VNXXT0ev4K8r98vHxkUGYMm93aByU+CR5X8a9WLcqFuLQHz7RD+TUfv26GJeGfRCoGWIj62L4pQYtrVg2DoOIQTG/+8PHL4hCL1VSrOt1N6tgvH1Y3eY/eVcWqHD+gOX0MRHheGdwuB+w+jm7OIKlGl08FIp4a1yw95zuXjjx1M4dbUmVP083PDW5DiM7BSGJdvS8N72MzdeplZT4iPx0rhO+L8V++SgrfbtE33Rs2UwAOCjpHSjmby++WtfxEdX7dPo9Hhp4xGs3ZdpdP6dcREY3rEpEtqGIvh6CxUwDVqFBIT5e8JbpYTP9cFjTw9ra3LfeVd6Lu5fthtAVZj+/txQNPP3xMyvUvHTsZrBavfGt0DvVsGYt+6QyedVKRVoGeKN09eqAqt9mB86R/hjvZlFMdyVEiRJklvThv4xpgMeGxhjsr2+3v75lNHfU7MAT/wydxDcFBJGLEnCxbyq1v6ANk3w+cO95H8XRWotnlp1ADvTsiFJVfu7RwXh3V9rFrX4112dMc1g0piGSM8uwYXcUvSLaWLRUfJCCPxxJhdLd5xBSnoulAoJS+7tZvS8vL0pUmtRUKpFVIi3rYtySxi2tWDYOhbD1ofKTYG/DWmDRxNa4fUfT+KLXReMjt34ZH90axFosWtX6gU2HLiEFSnnEejtjgXju6BVk5rWwQ9HLuPVzceNHmUCqgIqyFsFvRByiwoA/D3dUKQ27Yru0twf3z05AIczCzD5w13yQhATuzfH4nu7mRy/PjUTL208avKFQ5KAtk194e/pDi+VEocuFsjXUyokvHd/d4wx6BKujRACQxbtkFugTw9vC41Oj6XXH6sCqkawL57SDUqFZHR/udqC8Z3RrUUg7nr/D7PXuCsuAttPXjPpmle5KdAuzBdHLxXJ5V494w7EtwxCdkkFcks0aBvma/JlyZzs4goMeus3k3p6qG9LhPl74q2tpwBUdQv/9PRAtGnqa3ScEAJHLhUizN9Tfu549poD8uxoPiolfpk7yOT558JyLZb/cR5p14qRmVeGzPxylGp06BIRgD6tgxEfHYzTV4vx3cEsHMuq+pwdwv3w5aN9EOpnOtK/LrvP5uLdX0/jYn4Zgr1VCPRWIaekQn7vaoHe7vjN4JbBjTYcyMSKlAuIbxmE2cPb3tJYhNIKHbzclbc0YFCvF/j9TA5+P5ODXem5OJZVCL0AhnZoijcmxTaoLmzBocNWrVbjtddew+rVq5GRkYHg4GAkJiZiwYIFiIy8vZGNDFvHs/bPi0jPLsH9vaMQbRB2X+46L4+enRIfiTfvibvJu1iHXi9Qpq2EXgjo9QJCAP5e7lAqJBSWafF/X/xpcn8TAPq3CTHqjn1hdAd8ufsCMvOrWloRAZ74YXYCAr3N/2I8c60ET61KrVd3ttv1oB1dj6CttnTHGbz5U1UY+aiU8mAqoKpr+dNp8fJ98dIKHe58/3ecza7qzr8zLgLv3tcNkmQ+iHtEBWLt431x5FIhHvp0rzzi2s/TDZ88FI92YX4Y+26y/CXG010BISAPEmsf5odPpsWjRfDNW0D/2nQMn/9x3mS7JFUNOque6ezRAa3w8rhO9aqXnJIKDF+cJH+JGt4xDMsequnq1lbq8Zdle7D3fN7N3sas1qE+WPV/dxjN3nYzRWotXvvhJFbvzaj3NQwHwxla/sc5/HNTzTSszQI88Z+JXTHk+v302pRU6LBw03Gs238RwT4eGBfbDHd3b464yABU6PS4UqhGdkkFWoZ4o6lfzee6mFeGeesOmfTyVAvxUeGtybFyl789c9iwVavVGDZsGFJSUtCsWTMkJCTg/Pnz2Lt3L0JDQ7Fr1y7ExDS8W4lh61zO5ZQi/VoJBrUPrVdrp7GptZX42+oD+MVgOsxJPSLx5j2xmLv2oMkc0kBVd+/Xj/dFr+vdx7XR6PT4+fgV7DiVjZ1p2WbvlbopJLz/QHckdql/0AJVz5z2fX270UAnoOrRo2+f6GfS6rmQW4pXt5xAqJ8HXhzTET7XH7u6WqTGkEU75Naln4cbfpidIAfl4cwC/GvTcaiUCrxyZyd0bFY16OhARj6mfLQL2krzv8ZCfFT4+KF49GwZBKDqS09OaQWCvVVwUyqQmV+GoYuSoLn+HPBziR2w4UCmyX3YYB8Vfntm8C0NxFq37yKe/eaw/Hr2sLaYc33+8H9vOY5lyedqO7VOUcHe+HBqT1ToKnEhtwylGh0S2oQada3q9QJbjlzGws3Hzf6dG0po2wQtQ7yxcndVIEsSsHFmf8QZ9AB9/sc5/GuT+fnOh3cMQ6C3O9TaSmgr9Wgf5ofhncLQJSIABzMLMOfrg7iQa/o8tq+Hm1GvhUIChnYIw1/6RCGvVIP53x8zO+DwRmO6hqNr80C0DvVBTKgvWoZ4293/c4cN21deeQULFy5E37598fPPP8PXt6prZ/HixZg3bx4GDhyIpKSkBr8/w5Yam65Sj7d/ScP3B7MwvlsE5o1sD6VCwpVCNYa+vcOkm3PeiHb4m8Fzq/UhhMCpq8U4n1OKMk0lyjSVqNDp0adVcINngprxxT6jLwkhPipsfLJ/nS3KG1X/MlcqJLx7X3eMja1f8H+5+wJe3ni01v0qNwUeH9gaZ7NLsetsLvJKNQjwcseQ9qHIK9PKE5g0C/DEb88MxvHLRZj0QYrRdKD/mdAVD/SJquUK5gkhMPXTPUY9E8+Oao+YUB/8dWXNI2ZD2odiXGwEWgR7Q6mQsO98Hvacy8PhzAIEeqswpks47uoWgR+PXMHbv6TVej2FBIyNjcDjA1vjSqEab/+ShhOXjbuIO4T7YfawttDqBfJLNajQVaJfTBN0aR4AbaUeY95Jlu+fx0YGYMPM/tBW6rEi5bzRGIEmvh4oLNfU+iWnWlM/D+SWaky+jDXEgDZNMLRDU/SNCcG+83l4dcsJo0fdDCkVElJfHtEoj4XVl0OGrVarRdOmTVFQUIDU1FR07248j21cXBwOHz6Mffv2oWfPng26BsOW7MmHSel43eCXXb+YEHz5aB+7GOW6/eRVPLJ8H4CqYFs9o488kOtWHcjIh7fKDe3Db20ClYMXC3C1SI0WQd5oEeyFn49dxfPrD9cZBoZen9gV910fcf3P749h+fVFMDo288fmvw1oUF3nllTgvo93ywEGVNWRxqCre+OT/U0e66rNsp1n8e8fTtxyOVRuCswe1haPDWx90xaf4aA3oGqU+5nsEqNBaZFBXlg94w6UaSrx928O1XuEvkICnhzSBhGBXvju4CXsOZcnf6FRSICPys1kchag6rbBwvFdML5bhNGgxtNXizFrzUGTLxRAVU9E6ssj6lWuxlL7nHt27Pfff0dBQQFiYmJMghYA7rnnHhw+fBibNm1qcNgS2ZNH+rfCdwezcOJyEZr6eWDJvd3sImgBYEj7pnhySAx2n83DrGFtGxy0ANA9KqhB59044G1Sz0hEBnnh8ZX7jQaf1aZVEx/cYzCD1fOjO0Cn1yOrQI35d3ZqcF2H+Hrgq//rg3s/3i0/elYdXL4ebvhgao96By0AzBjYGl4qJf616Ri0lQJ+Hm6ICvFGsVqHjFqmzRzTNRzPjGxvNGFIbfrGhOCuuAh8f6jqtsXxG4IsMsgLax67A5FBVb0W3z7RD5sPX8bxy0XwdFPAw12JSr3A76dzsO9CnjzNaotgL/z33m7yv437e0fhapEamfnlCPP3QJi/J5SShOQzOVi15wK2nbiGSr1A39YhWDQlzuxz4m3D/LDxyX746egVHL1UiLPZpUjPLkFGXhlaN7G/x5ccsmX73//+F3PmzMHkyZOxdu1ak/1btmzBuHHjcPfdd2PDhg0NugZbtmRvitRa/HE6B71bBSPEzLzTZOp8Tile3HgEeaVa9GkVjP5tmiA2MgCpF/Lxy/Gr2JGWDYUk4cOpPeRHp6zhcmE5pny0S36ECAA+nNrjlu+RVyss16JSLxDk7Q5JklCpF9h67Ao+2JEuz5M9tENTzB3R7pZvD1wtUmPY20lG90p9VEoMbt8UL47tWO9VpXJLKpCUlo1STSXu7hZxS6OWc0oqcLVIjU7N/G/5+ekKXSUKy7VGA63sgUOG7dy5c7FkyRLMmTMHixcvNtl/6NAhdOvWDT169MD+/fvNvEON6lC9UXp6OmJiYhi2RGQRF/PKMP3zvUjPLsWc4e0we/it3W+vj+rHkDzdlWgXdmtd8YZSM/Kxek8GIgK9MKBtE3RrEWh3A44cjUN2I5eUVN3/8PY2PwDDx8fH6DgiIltrEeyNn54eiLKKSqstUiBJksk80g3RIyoIPRrYpU/mOWTYVjfGa+teuJXGem0t19pavEREDeWuVCDAmy1EV+SQf+t+flXdI6WlpWb3l5VVDRSofhyIiIjIlhwybKOiqobnZ2Zmmt1fvb36OCIiIltyyLCNi6uabi811fzao9XbY2NjG61MREREtXHIsO3fvz8CAgKQnp6OAwcOmOz/5ptvAADjxo1r7KIRERGZcMiwValUeOqppwAATz31lNG928WLF+Pw4cMYMGAAevXqZasiEhERyRzyOVugaiGCwYMHY8+ePfJCBBcuXMCePXsQEhKC3bt3o02bNg1+f05qQUREluKwYQsA5eXleO2117Bq1SpcvHgRQUFBSExMxMKFC9GiRYvbem8/Pz9otdrbWjmIiIgcU0xMDL7//nuLvZ9Dh601hYeHo7S09LZHNKenVy2kzdA2xnqpHevGPNaLeayX2t1O3TBsHQy7o81jvdSOdWMe68U81kvt7KluHHKAFBERkSNh2BIREVkZw5aIiMjKGLZERERWxrAlIiKyMo5GJiIisjK2bImIiKyMYUtERGRlDFsiIiIrY9gSERFZGcOWiIjIyhi2REREVsawJSIisjKGLRERkZUxbK1ArVZj/vz5aNeuHTw9PREREYFHHnkEmZmZti6aVZWVlWHjxo149NFHERsbC39/f/j4+CAuLg4LFixASUlJred+8cUX6N27N3x9fREcHIwxY8YgJSWlEUvfuPLy8tC0aVNIkoQOHTrc9FhXqZsrV65gzpw5aNeuHby8vBAcHIyePXvi73//u9njXaVedu/ejUmTJiE8PBzu7u4IDg7GsGHD8M0339R6jjPUzf79+/H6669j4sSJaN68OSRJgqenZ53nNeSzp6SkYMyYMQgODoavry969+6NFStWWOqjVBFkUeXl5aJfv34CgGjWrJmYMmWK6N27twAgQkNDxZkzZ2xdRKtZtmyZACAAiM6dO4vJkyeLUaNGCT8/PwFAdOjQQVy9etXkvDlz5ggAwsvLS4wfP16MGjVKuLm5CaVSKdavX2+DT2J906ZNE5IkCQCiffv2tR7nKnWTkpIiAgMDBQDRqVMnMWXKFDF69GjRsmVLoVQqTY53lXpZu3atUCgUAoCIj48X9957r0hISJC3PffccybnOEvdjB8/Xv59Uv3Hw8Pjpuc05LOvX79eKJVKIUmSGDRokJg0aZL8b3HOnDkW+zwMWwt7+eWXBQDRt29fUVxcLG9/++23BQAxcOBAG5bOulasWCGeeOIJkZaWZrQ9KytLdO/eXQAQ999/v9G+X3/9VQAQISEhRuelpKQIlUolAgICRF5eXqOUv7Fs27ZNABCPPfbYTcPWVerm0qVLIjAwUHh5eZn9hbhnzx6j165SL1qtVoSGhgoAYs2aNUb7UlJShKenp5AkyegLvDPVzeuvvy5eeeUVsWnTJnHlypU6w7Yhnz0vL08EBAQIAOLbb7+Vt1+5ckW0adNGABDbt2+3yOdh2FqQRqORvxGlpqaa7I+NjRUAxL59+2xQOttKSUmR/7NUVFTI28eMGSMAiCVLlpicM2vWLAFALFq0qBFLal1lZWWiTZs2olOnTiItLe2mYesqdfPggw8KAOK9996r1/GuUi9HjhyRe4TMqW75ff311/I2Z66busK2IZ/9zTffFADE+PHjTc5Zv369ACDGjRt3u0UXQjBsLWr79u0CgIiJiTG7f8GCBQKAmD9/fuMWzA6UlpbKXUFZWVlCiKoudw8PDwFAXLx40eScnTt3CgBi0KBBjVxa63nuueeEJEkiKSlJnDt3rtawdZW6ycvLEx4eHiIgIECUl5fXebyr1IsQQv4yVlfY/vLLL0II56+bm4VtQz/7wIEDBQDx5ZdfmpxTUVEhPD09haenZ73+bdZZ/tt+B5ItWbJEABCTJ082u3/z5s0CgLj77rsbuWS2V/0t3d3dXajVaiGEEAcOHJDvZZtTUlIiAIigoKDGLKrVHDp0SLi5uYlHHnlECCFuGrauUjebNm0SAMTYsWOFTqcT69atE7NnzxYzZ84U7777rrhy5YrR8a5SL0IIodPpROvWrU1ar0LUdCO3atVK7ily9rq5Wdg29LNX90QeO3bM7Hnx8fECgDh48ODtFV4IwdHIFpSRkQEAiIyMNLu/env1ca7knXfeAQAkJibCw8MDQN315ePjg8DAQOTn56O4uLhxCmoler0eM2bMQGBgIN588806j3eVujl27BgAICwsDAkJCZg8eTLeeecdLF26FLNmzUJMTAzWrVsnH+8q9QIASqUSy5cvR0BAAO6991706tUL9913HwYNGoQBAwagW7du+Pnnn6FSqQC4Vt3cqCGfvaioCAUFBTc9z5K/sxm2FlT9aIu3t7fZ/T4+PkbHuYoffvgBn376Kdzd3bFw4UJ5e131BThPnb333nvYu3cv3nrrLYSEhNR5vKvUTX5+PoCqxzUOHz6MTz/9FNnZ2Th37hzmzp2L0tJSTJ06FYcPHwbgOvVSLSEhAUlJSWjVqhX27duHr7/+Gjt37oSPjw+GDx+OiIgI+VhXqxtDDfnshnXQGL+zGbYWJIQAAEiSdNP9ruTEiROYOnUqhBB46623EBcXJ++rq74Mj3FkFy9exEsvvYRBgwZh+vTp9TrHVeqmsrISAKDT6bB48WI88sgjaNKkCaKjo/H222/jnnvugUajkXsDXKVeqq1evRp9+vRBVFQU9uzZg5KSEqSlpeH+++/Hq6++iuHDh0Or1QJwvbox1JDPXp+6sGR9MWwtyM/PDwBQWlpqdn9ZWRkAwNfXt9HKZEuZmZlITExEfn4+5s6di9mzZxvtr6u+AOeos5kzZ0Kj0eCDDz6o9zmuUjfVn1OhUGDatGkm+x955BEAwI4dO4yOd/Z6AYDTp09j2rRpCA0NxZYtW9C7d2/4+Pigbdu2+Oijj3DnnXdi165d+PzzzwG4Vt3cqCGfvfocw311nXM73G77HUgWFRUFALXOFFW9vfo4Z5aTk4MRI0YgIyMDDz/8MBYtWmRyTF31VVpaioKCAgQGBhr9x3A0mzdvRmBgIJ544gmj7Wq1GkDV/aDBgwfLx/r6+rpM3URHRwMAwsPD5Xv55vZfu3YNgOv8mwGANWvWQKvVIjExUe7ONDRlyhRs2rQJO3bswGOPPeZSdXOjhnx2f39/BAQEoLCwEJmZmejUqZPJeZb8nc2wtaDqLtLU1FSz+6u3x8bGNlqZbKG4uBijR4/GyZMnMXHiRCxbtsxs90779u3h4eGB7OxsZGZmmgxScKb6KigoQFJSktl95eXl8j6dTgfAdeqme/fuAKru3QohTP6d5ObmAqhpWbhKvQA1v+j9/f3N7q/enpeXB8C16uZGDf3scXFx2LlzJ1JTU03CVqvV4ujRo/Dw8ED79u1vu4zsRrag/v37IyAgAOnp6Thw4IDJ/uq5TMeNG9fYRWs0FRUVGD9+PPbt24dRo0Zh9erVUCqVZo/18vLC0KFDAcDsPK/OUl+i6hE7kz/nzp0DUPWLonpbYGAgANepm65du6JVq1YoLy/Hnj17TPZXdx/36NEDgOvUC1DV2geAffv2md3/559/Aqhp/btS3dyooZ997NixtZ6zefNmqNVqDBs2rF5zMtfpth8eIiMvvviiACD69esnSkpK5O3V0zUOGDDAhqWzLp1OJyZMmCAAiISEBFFaWlrnOb/88kutU6x5eHgIf39/kZuba81i28zNnrMVwnXq5sMPPxQARK9evUR2dra8fd++ffJzkOvWrZO3u0q97N+/X54IZunSpUb7du3aJXx8fIwmtRDCuesGdcwg1ZDPnpubK/z9/U2ma7x69ao8XeO2bdssU36LvAvJysvLRZ8+fQQMFiKofh0SEiJOnz5t6yJazX//+1/5l8OECRPEtGnTzP4x/IUqhBCzZ88WAIS3t7cYP368GD16tHBzcxMKhUJ88803Nvo01ldX2ArhGnVTWVkpJk+eLACI4OBgMW7cODF48GChUqkEADFjxgyTc1yhXoQQ4plnnpH/T1Uv7tG/f395IYLHHnvM5BxnqZvNmzeLPn36yH8ACEmSjLZt3rzZ6JyGfPZvvvlGKBQKIUmSGDx4sLjnnnvkL3mzZs2y2Odh2FpBWVmZePnll0VMTIxQqVQiLCxMTJs2TWRkZNi6aFY1f/58+RfDzf6cO3fO5NzPP/9c9OzZU3h7e4uAgAAxatQokZyc3PgfohHVJ2yFcI26qaysFP/73/9E9+7dhbe3t/Dx8RH9+vUTX3zxRa3nuEK9CFE1R+/IkSNFSEiIcHNzE0FBQWLIkCHiq6++qvUcZ6ibzz//vM7fJZ9//rnZ8271s//+++8iMTFRBAYGCm9vb9GzZ0/x2WefWfTzSEI46YNXREREdoIDpIiIiKyMYUtERGRlDFsiIiIrY9gSERFZGcOWiIjIyhi2REREVsawJSIisjKGLRERkZUxbImIiKyMYUtERGRlDFsiIiIrY9gS2TlJkur8M336dFsXs07Tp0+HJEnyGrVErsTN1gUgovqZNm1arfsGDBjQiCUholvFsCVyEMuXL7d1EYiogdiNTEREZGUMWyInJEkSoqOjodFoMH/+fMTExMDT0xOtW7fGK6+8ArVabfa83NxcPPvss2jbti08PT0RHByMxMRE/Pzzz7VeKycnBy+88AK6dOkCHx8fBAYGolu3bnjxxReRm5tr9pydO3di6NCh8PPzg7+/P8aOHYvjx49b5LMT2SMuHk9k5yRJAgDcyn9VSZIQFRWFuLg4bNu2DcOGDYNKpcKvv/6KwsJCDBs2DFu3boVSqZTPuXTpEgYOHIizZ88iKioKffv2RXZ2NpKSklBZWYnFixdjzpw5Rtc5fvw4Ro4ciUuXLqFZs2bo27cvKisrcerUKZw8eRK//fYbBg8eDKBqgNSKFSswd+5cvPPOO+jSpQvatGmDI0eOIC0tDSEhITh69CjCw8Nvv9KI7I0gIrsGQNzqf9XqcyIjI0V6erq8/dq1a6JLly4CgHjnnXeMzhk3bpwAIB588EGh0Wjk7cnJycLb21solUpx6NAhebtWqxUdOnQQAMS8efOMzhFCiNTUVHHx4kX59bRp0wQAoVAoxKpVq+TtOp1OTJo0SQAQL7/88i19TiJHwbAlsnPVwXmzPxs2bDB7zscff2zyfj/++KMAINq1aydvS09PFwCEv7+/yM/PNzln7ty5AoB4/PHH5W1ff/21ACBiY2NFZWVlnZ+jOmynTp1qsm///v0CgBg0aFCd70PkiDgamchB3OzRn6ioKLPb77vvPpNtiYmJCAoKQlpaGrKzsxEaGorff/8dADBmzBgEBgaanPPggw9i8eLFSE5Olrdt27YNADBjxgwoFPUf/jFy5EiTbe3atQMAXL58ud7vQ+RIGLZEDuJWH/0JCgqCn5+f2X0tW7ZEfn4+srKyEBoaiqysLABAdHS02eOrt1cfBwAXL14EAMTExNxSuSIjI022+fr6AgAqKipu6b2IHAVHIxO5IFHLYKvqwVi1bTe3v7ZzanOrxxM5A4YtkZPKz89HcXGx2X0ZGRkAgGbNmgEAIiIiAADnzp0ze/z58+eNjgeAFi1aAADOnDljkfISOTOGLZET+/rrr022bd26Ffn5+Wjbti2aNm0KoGa6xy1btqCgoMDknJUrVwIAEhIS5G3Dhw8HAHzyySe39FgSkSti2BI5sQULFsitUqBqAoq///3vAICZM2fK21u3bo2xY8eiuLgYs2fPhlarlfft2rULH3zwAZRKpdE5EydORLt27XDo0CE8//zz0Ol0Rtc+ePAgMjMzrfTJiBwLB0gROYibrewTFRWFBQsWmGyLjY1F586dMWzYMLi7u2P79u0oKCjAkCFD8NRTTxkd/9FHHyEhIQFffPEFkpKS5EktduzYgcrKSrz99tuIjY2Vj3dzc8O3336LESNG4M0338TKlSvRr18/6HQ6nDp1CidOnMBvv/1mdkAUkcux9bNHRHRzqMdztnFxcSbntGzZUqjVavGPf/xDREdHC5VKJVq2bClefPFFUVZWZvZaOTk5Yt68eSImJkaoVCoRGBgoRo4cKbZu3Vpr+a5cuSLmzZsn2rZtKzw8PERQUJDo1q2beOmll0Rubq58XPVztr/99lutn7Nly5a3Wj1EDoHTNRI5IUmS0LJlS6MuZCKyHd6zJSIisjKGLRERkZUxbImIiKyMo5GJnBCHYhDZF7ZsiYiIrIxhS0REZGUMWyIiIitj2BIREVkZw5aIiMjKGLZERERWxrAlIiKyMoYtERGRlTFsiYiIrIxhS0REZGUMWyIiIitj2BIREVkZw5aIiMjK/h984UO+UNQAuAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 495x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3.3,2),dpi=150)\n",
    "plt.plot(loss_hist)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.922\n",
      "Test accuracy: 0.915\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: %.3f\"%(compute_classification_accuracy(x_train,y_train, batch_size=256, shuffle=False)))\n",
    "print(\"Test accuracy: %.3f\"%(compute_classification_accuracy(x_test,y_test, batch_size=256, shuffle=False)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "59c89e211e6a7d15bcf1fda4d2617053683adc75be6d99dab9047beccd836cf8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
